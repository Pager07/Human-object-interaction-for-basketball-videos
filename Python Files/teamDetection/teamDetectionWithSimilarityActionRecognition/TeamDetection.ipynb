{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from GazeModule.ipynb\n",
      "importing Jupyter notebook from DrawPose.ipynb\n",
      "Successfully initalized general line:8\n",
      "(255, 255, 0)\n",
      "(255, 255, 0)\n",
      "(255, 255, 0)\n",
      "(255, 0, 255)\n",
      "(255, 255, 0)\n",
      "(255, 255, 0)\n",
      "(255, 255, 0)\n",
      "(255, 255, 0)\n"
     ]
    }
   ],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "from scipy.spatial import distance\n",
    "from sklearn.cluster import KMeans\n",
    "import import_ipynb\n",
    "import imutils \n",
    "import copy\n",
    "import GazeModule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File info:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Action Classification Similarity Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from ActionClassificationCosine.ipynb\n",
      "importing Jupyter notebook from ActionClassificationCosineDatasetGen.ipynb\n",
      "Loading Poses Data....\n",
      "Initializing VPTREE....\n",
      "VPTREE Ready To Use....\n",
      "importing Jupyter notebook from SinglePlayerPoseDatasetGen.ipynb\n",
      "importing Jupyter notebook from Tracker.ipynb\n"
     ]
    }
   ],
   "source": [
    "def weightedDistanceMatching(poseVector1,poseVector2):\n",
    "    '''\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    (poseVector1 : a 2D list pose vector of a human + theta [[poseVec],[thetaVector]]\n",
    "    theta : weigths for human pose vector\n",
    "    Example theta = [w_0x , w_0y.........w_17x, w_17y])\n",
    "    or \n",
    "    (poseVector1 : a 1D list pose vector of a human, used for building tree. \n",
    "    theta : A list with of ones. \n",
    "    Example [1,1,.....1] (17x1) )\n",
    "    \n",
    "    poseVector2 : pose vector that is to be compared with the human\n",
    "    \n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    ------------\n",
    "    weigtheDistance  : \n",
    "    '''\n",
    "    poseVector1 = np.array(poseVector1) \n",
    "    if poseVector1.shape[0] == 36:\n",
    "        poseVector1 = poseVector1.reshape(1,-1)\n",
    "        theta = np.ones_like(poseVector1)\n",
    "    elif poseVector1.shape[0] == 72:\n",
    "        poseVector1 = poseVector1.reshape(2,36)\n",
    "        theta = poseVector1[1]\n",
    "        poseVector1 = poseVector1[0]\n",
    "    \n",
    "    poseVector2 = np.array(poseVector2).reshape(1,-1)\n",
    "    term1 = 1/ np.sum(theta)\n",
    "    #Finding term 2\n",
    "    distanceTranspose = np.absolute(poseVector1 - poseVector2).transpose()\n",
    "    term2 = np.matmul(theta,distanceTranspose)\n",
    "\n",
    "        \n",
    "    \n",
    "    return term1 * term2\n",
    "\n",
    "def cosineDistanceMatching(poseVector1,poseVector2):\n",
    "    '''\n",
    "    Returns\n",
    "    -------\n",
    "    distacne: the cosine similarity as a distance function between the two L2 normalized vectors.\n",
    "    The distance is inversely porportional to the similarity between the two vectors\n",
    "    '''\n",
    "    poseVector1 , poseVector2 = np.array(poseVector1).reshape(1,-1) , np.array(poseVector2).reshape(1,-1)\n",
    "    cosineDistance = pairwise.cosine_distances(poseVector1 , poseVector2) \n",
    "    distance = np.sqrt(cosineDistance * 2)\n",
    "    return distance\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import ActionClassificationCosine\n",
    "import Tracker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#Loading and initialising yolov3 from opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "args = {\n",
    "          \"confThreshold\": 0.6,\n",
    "          \"nmsThreshold\":0.4,\n",
    "          \"inpWidth\":416,\n",
    "          \"inpHeight\":416,\n",
    "          \"bboxAreaToImageArea\":0.15,\n",
    "          \"knnLearner\" : None,\n",
    "          \"team0\":'MIL',\n",
    "          \"team1\":'CAVS',\n",
    "          \"colorBoundaries\":[\n",
    "                        ([ 56, -7 ,186], [196, 133, 266]), #white/team0/HSV/ FOR BASIC\n",
    "                        ([160-70,170-80, 60-30], [160+70,170+80, 60+30]) #red/team1/HSV\n",
    "                        ],\n",
    "          \"team0HSV\":[135,50,215], #white/team0/HSV/For KMEANS\n",
    "          \"team1HSV\":[170,50,70], #red/team1/HSV\n",
    "          \"yolo\": False,\n",
    "          \"mask-rcnn\" : False,\n",
    "          \"net\" : None,\n",
    "          \"output_layer_names\" : None\n",
    "        }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open(\"/Users/sandeep/Desktop/dataandmodles/models/teamDetection/coco.names\", 'rt') as f:\n",
    "    classes = f.read().rstrip('\\n').split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Get the names of the output layers of the CNN network\n",
    "# net : an OpenCV DNN module network object\n",
    "def getOutputsNames(net):\n",
    "    if args['yolo']:\n",
    "        # Get the names of all the layers in the network\n",
    "        layersNames = net.getLayerNames()\n",
    "        # Get the names of the output layers, i.e. the layers with unconnected outputs\n",
    "        return [layersNames[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "    else:\n",
    "        return [\"detection_out_final\", \"detection_masks\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def loadYolo():\n",
    "    rootDir = '/Users/sandeep/Desktop/dataandmodles/models/teamDetection'\n",
    "    args['net'] = cv2.dnn.readNet(rootDir+\"/yolov3.weights\",rootDir+\"/yolov3.cfg\")\n",
    "    net.setPreferableBackend(cv2.dnn.DNN_BACKEND_DEFAULT)\n",
    "    # change to cv2.dnn.DNN_TARGET_CPU (slower) if this causes issues (should fail gracefully if OpenCL not available)\n",
    "    net.setPreferableTarget(cv2.dnn.DNN_TARGET_OPENCL)\n",
    "    args['output_layer_names'] = getOutputsNames(args['net'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#Loading Mask-RCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def loadMaskRcnn():\n",
    "    #Load colors \n",
    "    RED_COLOR = np.array([255, 0, 0]) \n",
    "    BLACK_COLOR = np.array([255, 255, 255]) \n",
    "    # Load classes\n",
    "    classes_file = \"/Users/sandeep/Desktop/MaskRCNNopencv/mscoco_labels.names\"\n",
    "    text_graph = '/Users/sandeep/Desktop/dataandmodles/models/teamDetection/Mask_RCNN/mask_rcnn_inception_v2_coco_2018_01_28.pbtxt'\n",
    "    model_weights = '/Users/sandeep/Desktop/dataandmodles/models/teamDetection/Mask_RCNN/mask_rcnn_inception_v2_coco_2018_01_28/frozen_inference_graph.pb'\n",
    "\n",
    "    # load our Mask R-CNN trained on the COCO dataset (90 classes) from disk\n",
    "    print(\"[INFO] loading Mask R-CNN from disk...\")\n",
    "    args['net'] = cv2.dnn.readNetFromTensorflow(model_weights, text_graph)\n",
    "    args['output_layer_names'] = getOutputsNames(args['net'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#Opencv setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# dummy on trackbar callback function\n",
    "def on_trackbar(val):\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def openDisplayWindow():\n",
    "    windowName = 'YOLOv3 Team detection'\n",
    "    cv2.namedWindow(windowName , cv2.WINDOW_NORMAL) \n",
    "    trackbarName = 'reporting confidence > (x 0.01)'\n",
    "    cv2.createTrackbar(trackbarName,windowName,70,100, on_trackbar)\n",
    "    return windowName , trackbarName\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#HelperFunction:Drawing Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def drawPred(image,actionClass,team, confidence, left, top, right, bottom, colour,roi=None,mask=None):\n",
    "    \n",
    "    if args['yolo'] == False:\n",
    "        blended = ((0.4 * np.array(colour)) + (0.6 * roi)).astype(\"uint8\")\n",
    "        image[top:bottom, left:right][mask] = blended\n",
    "        \n",
    "    \n",
    "    # Draw a bounding box.\n",
    "    cv2.rectangle(image, (left, top), (right, bottom), colour, 1)\n",
    "\n",
    "    # construct label\n",
    "    label = '%s:%.2f' % (actionClass, confidence)\n",
    "    \n",
    "    #Display the label at the top of the bounding box\n",
    "    labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "    labelSize = (116,12)\n",
    "    top = max(top, labelSize[1])\n",
    "    pt1 = (left, top - round(1.5*labelSize[1])) \n",
    "    pt2 = (left + round(1.5*labelSize[0]), top + baseLine)\n",
    "    cv2.rectangle(image,pt1 , pt2 , colour, cv2.FILLED)\n",
    "    \n",
    "    cv2.putText(image, label, (left, top), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0,0,0), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#HelperFunction:Post Procces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def postprocess(image, results, threshold_confidence, threshold_nms, yolo=True, raw_masks=None):\n",
    "    frameHeight = image.shape[0]\n",
    "    frameWidth = image.shape[1]\n",
    "\n",
    "    # Scan through all the bounding boxes output from the network and..\n",
    "    # 1. keep only the ones with high confidence scores.\n",
    "    # 2. assign the box class label as the class with the highest score.\n",
    "    # 3. construct a list of bounding boxes, class labels and confidence scores\n",
    "\n",
    "    classIds = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "    masks = []\n",
    "    if yolo:\n",
    "        for result in results:\n",
    "            for detection in result:\n",
    "                scores = detection[5:]\n",
    "                classId = np.argmax(scores)\n",
    "                confidence = scores[classId]\n",
    "                if confidence > threshold_confidence:\n",
    "                    center_x = int(detection[0] * frameWidth)\n",
    "                    center_y = int(detection[1] * frameHeight)\n",
    "                    width = int(detection[2] * frameWidth)\n",
    "                    height = int(detection[3] * frameHeight)\n",
    "                    left = int(center_x - width / 2)\n",
    "                    top = int(center_y - height / 2)\n",
    "                    classIds.append(classId)\n",
    "                    confidences.append(float(confidence))\n",
    "                    boxes.append([left, top, width, height])\n",
    "    else:\n",
    "        for i in range(0, results.shape[2]):\n",
    "            classId = int(results[0, 0, i, 1])\n",
    "            confidence = results[0, 0, i, 2]\n",
    "            if confidence > threshold_confidence:\n",
    "                box = results[0, 0, i, 3:7] * np.array([frameWidth, frameHeight, frameWidth, frameHeight])\n",
    "                (left, top, right, bottom) = box.astype(\"int\")\n",
    "                boxW = right - left\n",
    "                boxH = bottom - top\n",
    "                mask = raw_masks[i, classId]\n",
    "                mask = cv2.resize(mask, (boxW, boxH), interpolation = cv2.INTER_NEAREST)\n",
    "                mask = (mask > 0.3)\n",
    "                classIds.append(classId)\n",
    "                confidences.append(float(confidence))\n",
    "                boxes.append([int(left), int(top), int(boxW), int(boxH)])\n",
    "                masks.append(mask)\n",
    "\n",
    "    # Perform non maximum suppression to eliminate redundant overlapping boxes with\n",
    "    # lower confidences\n",
    "    classIds_nms = []\n",
    "    confidences_nms = []\n",
    "    boxes_nms = []\n",
    "    masks_nms = []\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, threshold_confidence, threshold_nms)\n",
    "    for i in indices:\n",
    "        i = i[0]\n",
    "        classIds_nms.append(classIds[i])\n",
    "        confidences_nms.append(confidences[i])\n",
    "        boxes_nms.append(boxes[i])\n",
    "        if yolo == False:\n",
    "            masks_nms.append(masks[i])\n",
    "            \n",
    "    # return post processed lists of classIds, confidences and bounding boxes\n",
    "    if yolo:\n",
    "        return (classIds_nms, confidences_nms, boxes_nms)\n",
    "    else:\n",
    "        return (classIds_nms, confidences_nms, boxes_nms , masks_nms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#Filtering the preditction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def check_bbox_size(bboxW,bboxH,imgW,imgH):\n",
    "    bboxToImg = (bboxW*bboxH) / (imgW * imgH)\n",
    "    return bboxToImg <= args['bboxAreaToImageArea']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def check_label(label_id):\n",
    "    return label_id == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#ROI color detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def getRoi(frame, left,top,right,bottom,mask):\n",
    "    '''\n",
    "    Helper function for detect_teams\n",
    "    Returns ROI(region of interest) \n",
    "    '''\n",
    "    if args['yolo']:\n",
    "        roi = frame[top:bottom , left:right,:]\n",
    "    else:\n",
    "        roi = frame[top:bottom , left:right,:][mask]\n",
    "        \n",
    "    return roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def countNonBalckPix(roiMasked):\n",
    "    '''\n",
    "    Helper function for findColorRatio\n",
    "    Returns the number of non black pixels in the roi\n",
    "    '''\n",
    "    return roiMasked.any(axis = -1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def getColorRatio(roi,show=False):\n",
    "    '''\n",
    "    Helper function for detect teams\n",
    "    Returns a list, that contains percentage of the pixel that have the team %colors\n",
    "    Example: [0.9 , 0.1]. 90% of the pixels are of team 1\n",
    "    '''\n",
    "    ratioList = []\n",
    "    \n",
    "    for teamColorLower,teamColorUpper in args['colorBoundaries']:\n",
    "        mask = cv2.inRange(roi , np.array(teamColorLower) , np.array(teamColorUpper))\n",
    "        roiMasked = cv2.bitwise_and(roi,roi,mask=mask)\n",
    "        totalColorPix = countNonBalckPix(roiMasked)\n",
    "        totalPix = countNonBalckPix(roi)\n",
    "        colorPixRatio = totalColorPix / totalPix\n",
    "        ratioList.append(colorPixRatio)\n",
    "        #print(f'totalColrPix:{totalColorPix} , totalPx:{totalPix}')\n",
    "        if show == True:\n",
    "            cv2.imshow(\"images\", np.hstack([roi,roiMasked]))\n",
    "            if cv2.waitKey(0) & 0xFF == ord('q'):\n",
    "              cv2.destroyAllWindows() \n",
    "\n",
    "    return np.array(ratioList)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# img = cv2.imread('/Users/sandeep/Desktop/dataandmodles/data/cavs.JPG')\n",
    "# roi = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "# getColorRatio(roi, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def compareRatio(ratioList):\n",
    "    '''\n",
    "    Helper function for detectTeam\n",
    "    Finds the team with highest color ratio.\n",
    "    Returns string team names or \"Uncertain\" if not sure\n",
    "    '''\n",
    "    maxRatio = max(ratioList)\n",
    "    if maxRatio < 0.1:\n",
    "        return 'Uncertain'\n",
    "    else:      \n",
    "        if ratioList[1] > ratioList[0]:\n",
    "            return 'team1'\n",
    "        elif ratioList[1] <= ratioList[0]:\n",
    "            return'team0'\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def detectTeamBasic(img,left,top,right,bottom,mask=None):\n",
    "    '''\n",
    "    Given an image(BGR) and the location of ROI\n",
    "    Finds the team based on ROI color\n",
    "    '''\n",
    "    roi = getRoi(img,left,top,right,bottom,mask)\n",
    "    if args['yolo']:\n",
    "        roiHSV = np.array(cv2.cvtColor(roi, cv2.COLOR_BGR2HSV))\n",
    "    else:#For mask rcnn, roi will contain list of pixles in mask region\n",
    "        roi_reshaped = np.reshape(roi,(1,roi.shape[0],3))\n",
    "        roiHSV = np.array(cv2.cvtColor(roi_reshaped, cv2.COLOR_BGR2HSV))\n",
    "\n",
    "    ratioList = getColorRatio(roiHSV)\n",
    "    team = compareRatio(ratioList)\n",
    "    \n",
    "    if args['yolo']:\n",
    "        return team\n",
    "    else:\n",
    "        return team , roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def getTeamInfo(team):\n",
    "    if team == 'Uncertain':\n",
    "        return (0,0,0) , 'Uncertain'\n",
    "    elif team == 'team0': \n",
    "        return (0,213,255) , args[team]\n",
    "    else:\n",
    "        return (36,36,158) , args[team]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#Team using K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def findHistogram(learner):\n",
    "    '''\n",
    "    Helper function for detectTeamsKmeans\n",
    "    Returns a histrogam object for an ROI\n",
    "    '''\n",
    "    numLabels = np.arange(0, len(np.unique(learner.labels_)) + 1)\n",
    "    (hist, _) = np.histogram(learner.labels_, bins=numLabels)\n",
    "    \n",
    "    hist = hist.astype(\"float\")\n",
    "    hist /= hist.sum()\n",
    "    return hist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def resizeForKMeans(roi):\n",
    "    '''\n",
    "    Helper function for detectTeamsKmenas\n",
    "    Given an roi in HSV space\n",
    "    Returns reshaped roi of (NumberofPixles x channels)\n",
    "    '''\n",
    "    return roi.reshape((roi.shape[0] * roi.shape[1],3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def getClustersAndPercatage(hist , learner):\n",
    "    '''\n",
    "    Helper function for detectTeansKmeans\n",
    "    Returns a dict with cluster object {'c1':[h,s,v,percentage] , c2:[..]}\n",
    "    '''\n",
    "    clusters = {}\n",
    "    for index,(percent, color) in enumerate(zip(hist, learner.cluster_centers_)):\n",
    "        colorList = color.astype(\"uint8\").tolist()\n",
    "        cluster = f'c{index}'\n",
    "        clusters[cluster] = [colorList[0], colorList[1], colorList[2], int(percent*100)]\n",
    "    return clusters\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def getLargestCluster(clusters):\n",
    "    '''\n",
    "    Helper function for detectTemsKmeans\n",
    "    Returns the name/key of the largest cluster in the clusters dict\n",
    "    '''\n",
    "    percentages = np.array([clusters[cluster][3]for cluster in clusters])\n",
    "    max_index = np.argmax(percentages)\n",
    "    return list(clusters.keys())[max_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def getEuclidianDistance(hsv1,hsv2):\n",
    "    return distance.euclidean(hsv1,hsv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def getLearner(nClusters):\n",
    "    '''\n",
    "     Returns a KMeans Learner object\n",
    "    '''\n",
    "    learner = KMeans(n_clusters=nClusters) #cluster number\n",
    "    return learner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def detectTeamKmeans(learner,img,left,top,right,bottom,mask=None):\n",
    "    '''\n",
    "    Given an image(BGR) and the location of ROI\n",
    "    Returns the team using K-Means clustering\n",
    "    '''\n",
    "    roi = getRoi(img,left,top,right,bottom,mask)\n",
    "    if args['yolo']:\n",
    "        roiHSV = np.array(cv2.cvtColor(roi, cv2.COLOR_BGR2HSV))\n",
    "    else:\n",
    "        roiReshaped = np.reshape(roi,(1,roi.shape[0],3))\n",
    "        roiHSV = np.array(cv2.cvtColor(roiReshaped, cv2.COLOR_BGR2HSV))\n",
    "    \n",
    "    roiHSV = resizeForKMeans(roiHSV) #represent as (row*column,channel number) eg. [[0,0,255],[..]]\n",
    "    learner.fit(roiHSV)\n",
    "    hist = findHistogram(learner)\n",
    "    clusters = getClustersAndPercatage(hist,learner) #clusters is a dict {c1:[h,s,v,perc],c2:[]}\n",
    "    hsv = clusters[getLargestCluster(clusters)][:-1] # is a list [h,s,v]\n",
    "\n",
    "    teamIndex = np.argmin(np.array([\n",
    "                                getEuclidianDistance(hsv, args['team0HSV']),\n",
    "                                 getEuclidianDistance(hsv, args['team1HSV'])\n",
    "                     ]))\n",
    "    team = f'team{teamIndex}'\n",
    "    #hsv is returned for testing purposes. To check the k-means cluster mean\n",
    "    return team,hsv,roi\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#Controller to switch between basic and Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def detectTeam(img,left,top,right,bottom, algo='basic', mask=None, learner=None):\n",
    "    if algo == 'basic':\n",
    "        if args['yolo']: #yolo\n",
    "            return detectTeamBasic(img,left,top,right,bottom)\n",
    "        else: #mask rcnn\n",
    "            return detectTeamBasic(img,left,top,right,bottom,mask)\n",
    "    else:\n",
    "        if args['yolo']:#yolo with k-means\n",
    "            return detectTeamKmeans(learner,img,left,top,right,bottom)\n",
    "        else: #mask-rcnn with k-means\n",
    "            return detectTeamKmeans(learner,img,left,top,right,bottom,mask)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#Object detection boiler template (YOLO) Basic or K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if args['yolo']:\n",
    "    videoPath ='/Users/sandeep/Desktop/dataandmodles/data/3-Pointer2.mov'\n",
    "    cap = cv2.VideoCapture(videoPath)\n",
    "    frameCount = 0 \n",
    "    rawFrame=[]\n",
    "    learner = getLearner(3)\n",
    "    net = args['net']\n",
    "    output_layer_names = args['output_layer_names']\n",
    "    while cap.isOpened():\n",
    "        ret,frame = cap.read()\n",
    "        frameCopy = frame[:]\n",
    "        if ret:\n",
    "            start_t = cv2.getTickCount()\n",
    "\n",
    "            #do stuff\n",
    "            # create a 4D tensor (OpenCV 'blob') from image frame (pixels scaled 0->1, image resized)\n",
    "            tensor = (cv2.dnn.blobFromImage(frame , 1/255 , (args[\"inpWidth\"], args[\"inpHeight\"]) , [0,0,0] , 1, \n",
    "                                            crop=False))\n",
    "            # set the input to the CNN network\n",
    "            net.setInput(tensor)\n",
    "            results = net.forward(output_layer_names)\n",
    "\n",
    "            args['confThreshold'] = cv2.getTrackbarPos(trackbarName,windowName) / 100\n",
    "            classIDs, confidences, boxes = (postprocess(frame, results, args[\"confThreshold\"], \n",
    "                                                        args[\"nmsThreshold\"]))\n",
    "            for detected_object in range(0, len(boxes)):\n",
    "\n",
    "                box = boxes[detected_object]\n",
    "                left = box[0]\n",
    "                top = box[1]\n",
    "                width = box[2]\n",
    "                height = box[3]\n",
    "\n",
    "                bboxFit = check_bbox_size(width,height, *frame.shape[0:-1])\n",
    "                labelFit = check_label(classes[classIDs[detected_object]])\n",
    "                if bboxFit and labelFit and left>0:\n",
    "                    team,hue= detectTeam(frameCopy, left ,top, left+width,top+height , algo='kmeans' ,\n",
    "                                     learner=learner)\n",
    "\n",
    "                    teamColor, teamName = getTeamInfo(team)\n",
    "                    teamName = f'{team},{hue}'\n",
    "                    (drawPred(frame,teamName,classes[classIDs[detected_object]], \n",
    "                              confidences[detected_object], \n",
    "                              left, top, left + width, top + height, \n",
    "                              teamColor))\n",
    "\n",
    "                t,_ = net.getPerfProfile()\n",
    "                inference_t = (t * 1000.0 / cv2.getTickFrequency())\n",
    "                label = ('Inference time: %.2f ms' % inference_t) + (' (Framerate: %.2f fps' % (1000 / inference_t)) + ')'\n",
    "                cv2.putText(frame, label, (0, 15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255))\n",
    "                if frameCount == 496: \n",
    "                    print(f'{left},{top},{left + width},{top + height}')\n",
    "                    rawFrame = frame[:,:,:]\n",
    "                frameCount += 1\n",
    "    #         End of do stuff\n",
    "\n",
    "            cv2.imshow(windowName,frame)\n",
    "            (cv2.setWindowProperty(windowName, cv2.WND_PROP_FULLSCREEN,\n",
    "                                    cv2.WINDOW_FULLSCREEN&False))    \n",
    "\n",
    "            time_now = cv2.getTickCount()\n",
    "            stop_t = ((time_now - start_t)/cv2.getTickFrequency())*1000\n",
    "\n",
    "            #cv2.imshow(\"YOLO\" , frame)\n",
    "\n",
    "            key = cv2.waitKey(max(2, 40 - int(math.ceil(stop_t)))) & 0xFF\n",
    "            if key == ord('q'):\n",
    "                break  \n",
    "        else:\n",
    "            cap.release()\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Object detection boiler template (MASK RCNN) Basic or Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitMaskRcnn(frame):\n",
    "    net = args['net']\n",
    "    output_layer_names = args['output_layer_names']\n",
    "    tensor = cv2.dnn.blobFromImage(frame, swapRB=True, crop=False)\n",
    "    net.setInput(tensor)\n",
    "    (boxes, masks) = net.forward([\"detection_out_final\", \"detection_masks\"])\n",
    "    classIDs, confidences, boxes, masks = (postprocess(frame, boxes, args[\"confThreshold\"], \n",
    "                                          args[\"nmsThreshold\"],yolo=False,raw_masks=masks))\n",
    "    return classIDs,confidences,boxes,masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBoxesAndMask(boxes,masks,detected_object_index):\n",
    "    box = boxes[detected_object_index]\n",
    "    mask = masks[detected_object_index] #getting the mask of a particular detected obj\n",
    "    left = box[0]\n",
    "    top = box[1]\n",
    "    width = box[2]\n",
    "    height = box[3]\n",
    "    return left,top,width,height,mask\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "args['mask-rcnn'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:24\n",
      "Player Detection:2.21,Action Classification:0.3,Team Detection:0.07\n",
      "Successfully initalized general line:22\n",
      "Player Detection:2.18,Action Classification:0.32,Team Detection:0.07\n",
      "Successfully initalized general line:23\n",
      "Player Detection:2.21,Action Classification:0.32,Team Detection:0.07\n",
      "Successfully initalized general line:23\n",
      "Player Detection:2.15,Action Classification:0.3,Team Detection:0.07\n",
      "Successfully initalized general line:23\n",
      "Player Detection:2.2,Action Classification:0.29,Team Detection:0.07\n",
      "Successfully initalized general line:22\n",
      "Player Detection:2.22,Action Classification:0.3,Team Detection:0.06\n",
      "Successfully initalized general line:24\n",
      "Player Detection:2.19,Action Classification:0.3,Team Detection:0.07\n",
      "Successfully initalized general line:25\n",
      "Player Detection:2.21,Action Classification:0.29,Team Detection:0.07\n",
      "Successfully initalized general line:25\n",
      "Player Detection:2.17,Action Classification:0.31,Team Detection:0.06\n",
      "Successfully initalized general line:24\n",
      "Player Detection:2.17,Action Classification:0.3,Team Detection:0.06\n",
      "Successfully initalized general line:26\n",
      "Player Detection:2.15,Action Classification:0.29,Team Detection:0.07\n",
      "Successfully initalized general line:26\n",
      "Player Detection:2.25,Action Classification:0.29,Team Detection:0.06\n",
      "Successfully initalized general line:22\n",
      "Player Detection:2.1,Action Classification:0.29,Team Detection:0.06\n",
      "Successfully initalized general line:25\n",
      "Player Detection:2.07,Action Classification:0.29,Team Detection:0.07\n",
      "Successfully initalized general line:24\n",
      "Player Detection:2.06,Action Classification:0.3,Team Detection:0.06\n",
      "Successfully initalized general line:20\n",
      "Player Detection:2.1,Action Classification:0.29,Team Detection:0.06\n",
      "Successfully initalized general line:25\n",
      "Player Detection:2.09,Action Classification:0.28,Team Detection:0.06\n",
      "Successfully initalized general line:23\n",
      "Player Detection:2.08,Action Classification:0.28,Team Detection:0.07\n",
      "Successfully initalized general line:22\n",
      "Player Detection:2.19,Action Classification:0.28,Team Detection:0.07\n",
      "Successfully initalized general line:23\n",
      "Player Detection:2.13,Action Classification:0.28,Team Detection:0.06\n",
      "Successfully initalized general line:23\n",
      "Player Detection:2.13,Action Classification:0.3,Team Detection:0.06\n",
      "Successfully initalized general line:20\n",
      "Player Detection:2.28,Action Classification:0.31,Team Detection:0.07\n",
      "Successfully initalized general line:24\n",
      "Player Detection:2.23,Action Classification:0.29,Team Detection:0.07\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-fb3c298c8e62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     77\u001b[0m                     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                     \u001b[0;31m#resizedRoiWithPose = drawPose(resizedRoi)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                     \u001b[0mactionClass\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mposenetPred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mposenetBoxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetActionClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresizedRoi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m                     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-2c8f8c5bb5d6>\u001b[0m in \u001b[0;36mgetActionClass\u001b[0;34m(resizedRoi)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bbox'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         classes = ActionClassificationCosine.fit(poses,boxes,resizedRoi.shape[0] ,\n\u001b[0;32m---> 50\u001b[0;31m                                                  resizedRoi.shape[1])\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'unknown'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/FinalYearProject/Python Files/teamDetection/teamDetectionWithSimilarityActionRecognition/ActionClassificationCosine.ipynb\u001b[0m in \u001b[0;36mfit\u001b[0;34m(posenetPred, bboxes, inputImgH, inputImgW, cosine)\u001b[0m\n",
      "\u001b[0;32m~/Desktop/FinalYearProject/Python Files/teamDetection/teamDetectionWithSimilarityActionRecognition/ActionClassificationCosine.ipynb\u001b[0m in \u001b[0;36mgetPred\u001b[0;34m(poses)\u001b[0m\n",
      "\u001b[0;32m~/Desktop/FinalYearProject/Python Files/teamDetection/teamDetectionWithSimilarityActionRecognition/ActionClassificationCosine.ipynb\u001b[0m in \u001b[0;36mfindMatch\u001b[0;34m(pose)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cv/lib/python3.7/site-packages/vptree.py\u001b[0m in \u001b[0;36mget_nearest_neighbor\u001b[0;34m(self, query)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mSingle\u001b[0m \u001b[0mnearest\u001b[0m \u001b[0mneighbor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \"\"\"\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_n_nearest_neighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_n_nearest_neighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cv/lib/python3.7/site-packages/vptree.py\u001b[0m in \u001b[0;36mget_n_nearest_neighbors\u001b[0;34m(self, query, n_neighbors)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdist_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mfurthest_d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                 \u001b[0mneighbors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-e1955b23d25c>\u001b[0m in \u001b[0;36mweightedDistanceMatching\u001b[0;34m(poseVector1, poseVector2)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mweigtheDistance\u001b[0m  \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     '''\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mposeVector1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposeVector1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mposeVector1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m36\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mposeVector1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mposeVector1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if args['mask-rcnn']:\n",
    "    windowName , trackbarName = openDisplayWindow()\n",
    "\n",
    "    #loadMaskRcnn()\n",
    "    net = args['net']\n",
    "    output_layer_names = args['output_layer_names']\n",
    "    \n",
    "    videoPath ='/Users/sandeep/Desktop/dataandmodles/data/3-Pointer2.mov'\n",
    "    cap = cv2.VideoCapture(videoPath)\n",
    "    frameCount = 0 \n",
    "    rawFrame=[]\n",
    "    \n",
    "    #TeamDetection Learner\n",
    "    learner = getLearner(3)\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret,frame = cap.read()\n",
    "        frameCopy = frame[:]\n",
    "        h,w = frame.shape[0] , frame.shape[1]\n",
    "        #Time Logs for each new frame\n",
    "        actionTimes = np.array([]) \n",
    "        teamDetectionTimes = np.array([])\n",
    "        playerDetectionTimes = np.array([])\n",
    "        \n",
    "        \n",
    "        if ret:\n",
    "            start_t = cv2.getTickCount()\n",
    "            #do stuff\n",
    "            args['confThreshold'] = cv2.getTrackbarPos(trackbarName,windowName) / 100\n",
    "            start = time.time()\n",
    "            classIDs,confidences,boxes,masks = fitMaskRcnn(frame)\n",
    "            end = time.time()\n",
    "            playerDetectionTime = end  - start \n",
    "            playerDetectionTimes = np.append(playerDetectionTimes,playerDetectionTime)\n",
    "            \n",
    "            #Gaze detection variable\n",
    "            posenetPredCombined = {'detectionList':[]}\n",
    "            frame_bboxs = []\n",
    "            \n",
    "            #Drawing variables\n",
    "            frame_rois = []\n",
    "            frame_masks = []\n",
    "            frame_rcnnbboxes = []\n",
    "            frame_teamColors = []\n",
    "            frame_actions = []\n",
    "            \n",
    "            #Tracker Variables \n",
    "            frame_posenetbboxs = {'bbox':[]}\n",
    "            for detected_object in range(0, len(boxes)):\n",
    "\n",
    "                left,top,width,height,mask = getBoxesAndMask(boxes, masks, detected_object)\n",
    "\n",
    "                bboxFit = check_bbox_size(width,height, *frame.shape[0:-1])\n",
    "                labelFit = check_label(classIDs[detected_object])\n",
    "                if bboxFit and labelFit and left>0:\n",
    "                    #uncommet to use basic fast rcnn and remove hsv from teamName\n",
    "                    start = time.time()\n",
    "                    #team,roi= detectTeam(frameCopy, left ,top, left+width,top+height , algo='basic',mask=mask)\n",
    "                    team,hsv,roi= (detectTeam(frameCopy, left ,top, left+width,top+height , algo='kmeans',\n",
    "                                             learner=learner\n",
    "                                             ,mask=mask))\n",
    "                    \n",
    "                    end = time.time()\n",
    "                    teamDetectionTime = end - start \n",
    "                    teamDetectionTimes = np.append(teamDetectionTimes,teamDetectionTime)\n",
    "                    \n",
    "                    \n",
    "                    teamColor, teamName = getTeamInfo(team)\n",
    "                    teamName = f'{team},{hsv}'\n",
    "                    \n",
    "                    resizedRoi,roiCropped,leftLarger,topLarger,rightLarger,bottomLarger = transformRoiBoka(mask,\n",
    "                                                                                                       roi,frame,\n",
    "                                                                                                       h,w,left,top,\n",
    "                                                                                                       left+width,\n",
    "                                                                                                       top+height )\n",
    "\n",
    "                    start = time.time()\n",
    "                    #resizedRoiWithPose = drawPose(resizedRoi)\n",
    "                    actionClass,posenetPred,posenetBoxs = getActionClass(resizedRoi)\n",
    "                    \n",
    "                    end = time.time()\n",
    "                    actionTime = end - start \n",
    "                    actionTimes  = np.append(actionTimes, actionTime)\n",
    "                    \n",
    "                    posenetPred = mapPosesToMainImageWrapper(posenetPred,\n",
    "                                              topLarger, \n",
    "                                              leftLarger,resizedRoi,\n",
    "                                              roiCropped)\n",
    "                    \n",
    "                    #GAZE DETECTION PREP(Combine posenetPred for gaze detection):\n",
    "                    for pose in posenetPred['detectionList']:\n",
    "                        posenetPredCombined['detectionList'].append(pose)\n",
    "                    if len(posenetPred['detectionList']) != 0:\n",
    "                        frame_bboxs.append([leftLarger,topLarger,rightLarger,bottomLarger])\n",
    "                        frame_actions.append(actionClass)\n",
    "                        frame_masks.append(mask)\n",
    "                        frame_rois.append(roi)\n",
    "                        frame_rcnnbboxes.append([left ,top, left+width,top+height])\n",
    "                        frame_teamColors.append(teamColor)\n",
    "                    #END GAZE DETECTION PREP:\n",
    "                    #Tracker Prep\n",
    "                    frame_posenetbboxs['bbox'].extend(posenetBoxs['bbox'])\n",
    "                    #End Tracker Prep\n",
    "            \n",
    "            \n",
    "               #GAZE DETECTION tag1\n",
    "            if len(frame_bboxs):\n",
    "               ball_position,poseIndex = GazeModule.fitGazeModule(posenetPredCombined,frame_bboxs,frame_actions)\n",
    "               drawMaskRcnnHelperFunction(frameCopy,poseIndex,frame_rcnnbboxes,\n",
    "                               frame_teamColors,frame_actions,\n",
    "                               frame_rois,frame_masks)\n",
    "               DrawPose.drawBall(frameCopy,w,h,ball_position,(255,0,0),20)\n",
    "            #END GAZE DETECTION tag1\n",
    "            \n",
    "            #Tracker\n",
    "           \n",
    "            if len(list(Tracker.previousFramePose.keys())) != 0 :\n",
    "                #actions = [[f] for f in frame_actions]\n",
    "                finalActionClasses = Tracker.updatePosesClasses(posenetPredCombined,\n",
    "                                                          frame_actions,\n",
    "                                                          frame_posenetbboxs,\n",
    "                                                          frameCopy.shape[0],frameCopy.shape[1])\n",
    "                \n",
    "            \n",
    "            Tracker.setPrevFrameWrapper(frame_posenetbboxs,posenetPredCombined,\n",
    "                                                        frame_actions,\n",
    "                                                        frameCopy.shape[0],frameCopy.shape[1])\n",
    "            #End Tracker\n",
    "            \n",
    "            #Drawing boxes and ball\n",
    "            if len(frame_bboxs):\n",
    "               drawMaskRcnnHelperFunction(frameCopy,poseIndex,frame_rcnnbboxes,\n",
    "                                           frame_teamColors,finalActionClasses,\n",
    "                                           frame_rois,frame_masks)\n",
    "               DrawPose.drawBall(frameCopy,w,h,ball_position,(255,0,0),20)\n",
    "            \n",
    "    #       End of do stuff\n",
    "    \n",
    "    \n",
    "            #Print Time took for each part \n",
    "            timeString =   f'Player Detection:{round(np.mean(playerDetectionTimes),2)},Action Classification:{round(np.mean(actionTimes),2)},Team Detection:{round(np.mean(teamDetectionTimes),2)}'\n",
    "            print(timeString)\n",
    "            \n",
    "            # Prinint frame rate \n",
    "            t,_ = net.getPerfProfile()\n",
    "            inference_t = (t * 1000.0 / cv2.getTickFrequency())\n",
    "            label = ('Inference time: %.2f ms' % inference_t) + (' (Framerate: %.2f fps' % (1000 / inference_t)) + ')'\n",
    "            cv2.putText(frame, label, (0, 15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255))\n",
    "            #Displaying the image\n",
    "            cv2.imshow(windowName,frameCopy)\n",
    "            (cv2.setWindowProperty(windowName, cv2.WND_PROP_FULLSCREEN,\n",
    "                                    cv2.WINDOW_FULLSCREEN&False))    \n",
    "\n",
    "            time_now = cv2.getTickCount()\n",
    "            stop_t = ((time_now - start_t)/cv2.getTickFrequency())*1000\n",
    "            \n",
    "            #cv2.imshow(\"MASK-RCNN\" , frame)\n",
    "    \n",
    "            key = cv2.waitKey(max(2, 40 - int(math.ceil(stop_t)))) & 0xFF\n",
    "            if key == ord('q'):\n",
    "                break  \n",
    "        else:\n",
    "            cap.release()\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Writing Video file \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def detectVideos(frame):\n",
    "\n",
    "#     learner = args['knnLearner']\n",
    "#     net = args['net']\n",
    "#     output_layer_names = args['output_layer_names']\n",
    "    \n",
    "    \n",
    "#     h,w = frame.shape[0], frame.shape[1]\n",
    "#     frameCopy = np.copy(frame)\n",
    "    \n",
    "    \n",
    "#     classIDs,confidences,boxes,masks = fitMaskRcnn(frame)\n",
    "\n",
    "   \n",
    "#     for detected_object in range(0, len(boxes)):\n",
    "        \n",
    "#         left,top,width,height,mask = getBoxesAndMask(boxes, masks, detected_object)\n",
    "\n",
    "#         bboxFit = check_bbox_size(width,height, *frame.shape[0:-1])\n",
    "#         labelFit = check_label(classIDs[detected_object])\n",
    "#         if bboxFit and labelFit and left>0:\n",
    "#             #uncommet to use basic fast rcnn and remove hsv from teamName\n",
    "#             #team,roi= detectTeam(frameCopy, left ,top, left+width,top+height , algo='basic',mask=mask)\n",
    "#             team,hsv,roi= (detectTeam(frameCopy, left ,top, left+width,top+height , algo='kmeans',\n",
    "#                                      learner=learner\n",
    "#                                      ,mask=mask))\n",
    "            \n",
    "#             teamColor, teamName = getTeamInfo(team)\n",
    "#             teamName = f'{team},{hsv}'\n",
    "            \n",
    "#             resizedRoi,roiCropped,leftLarger,topLarger,rightLarger,bottomLargerresizedRoi = transformRoiBoka(mask,roi,frame,h,w,left,top,left+width,top+height)\n",
    "            \n",
    "#             actionClass = getActionClass(resizedRoi)\n",
    "\n",
    "#             (drawPred(frameCopy,actionClass,teamName, \n",
    "#                       confidences[detected_object], \n",
    "#                       left, top, left + width, top + height, \n",
    "#                       teamColor,roi=roi ,mask=mask))\n",
    "#     return frameCopy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectVideos(frame):\n",
    "    learner = args['knnLearner']\n",
    "    net = args['net']\n",
    "    output_layer_names = args['output_layer_names']\n",
    "    \n",
    "    h,w = frame.shape[0], frame.shape[1]\n",
    "    frameCopy = np.copy(frame)\n",
    "    \n",
    "    \n",
    "    classIDs,confidences,boxes,masks = fitMaskRcnn(frame)\n",
    "\n",
    "    #Gaze detection variable\n",
    "    posenetPredCombined = {'detectionList':[]}\n",
    "    frame_bboxs = []\n",
    "\n",
    "    #Drawing variables\n",
    "    frame_rois = []\n",
    "    frame_masks = []\n",
    "    frame_rcnnbboxes = []\n",
    "    frame_teamColors = []\n",
    "    frame_actions = []\n",
    "\n",
    "    #Tracker Variables \n",
    "    frame_posenetbboxs = {'bbox':[]}\n",
    "    for detected_object in range(0, len(boxes)):\n",
    "\n",
    "        left,top,width,height,mask = getBoxesAndMask(boxes, masks, detected_object)\n",
    "\n",
    "        bboxFit = check_bbox_size(width,height, *frame.shape[0:-1])\n",
    "        labelFit = check_label(classIDs[detected_object])\n",
    "        if bboxFit and labelFit and left>0:\n",
    "            #uncommet to use basic fast rcnn and remove hsv from teamName\n",
    "            #team,roi= detectTeam(frameCopy, left ,top, left+width,top+height , algo='basic',mask=mask)\n",
    "            team,hsv,roi= (detectTeam(frameCopy, left ,top, left+width,top+height , algo='kmeans',\n",
    "                                     learner=learner\n",
    "                                     ,mask=mask))\n",
    "\n",
    "#             end = time.time()\n",
    "#             teamDetectionTime = end - start \n",
    "#             teamDetectionTimes = np.append(teamDetectionTimes,teamDetectionTime)\n",
    "\n",
    "\n",
    "            teamColor, teamName = getTeamInfo(team)\n",
    "            teamName = f'{team},{hsv}'\n",
    "\n",
    "            resizedRoi,roiCropped,leftLarger,topLarger,rightLarger,bottomLarger = transformRoiBoka(mask,\n",
    "                                                                                               roi,frame,\n",
    "                                                                                               h,w,left,top,\n",
    "                                                                                               left+width,\n",
    "                                                                                               top+height )\n",
    "\n",
    "            \n",
    "            #resizedRoiWithPose = drawPose(resizedRoi)\n",
    "            actionClass,posenetPred,posenetBoxs = getActionClass(resizedRoi)\n",
    "\n",
    "   \n",
    "\n",
    "            posenetPred = mapPosesToMainImageWrapper(posenetPred,\n",
    "                                      topLarger, \n",
    "                                      leftLarger,resizedRoi,\n",
    "                                      roiCropped)\n",
    "\n",
    "            #GAZE DETECTION PREP(Combine posenetPred for gaze detection):\n",
    "            for pose in posenetPred['detectionList']:\n",
    "                posenetPredCombined['detectionList'].append(pose)\n",
    "            if len(posenetPred['detectionList']) != 0:\n",
    "                frame_bboxs.append([leftLarger,topLarger,rightLarger,bottomLarger])\n",
    "                frame_actions.append(actionClass)\n",
    "                frame_masks.append(mask)\n",
    "                frame_rois.append(roi)\n",
    "                frame_rcnnbboxes.append([left ,top, left+width,top+height])\n",
    "                frame_teamColors.append(teamColor)\n",
    "            #END GAZE DETECTION PREP:\n",
    "            #Tracker Prep\n",
    "            frame_posenetbboxs['bbox'].extend(posenetBoxs['bbox'])\n",
    "            #End Tracker Prep\n",
    "\n",
    "\n",
    "       #GAZE DETECTION tag1\n",
    "    if len(frame_bboxs):\n",
    "       ball_position,poseIndex = GazeModule.fitGazeModule(posenetPredCombined,frame_bboxs,frame_actions)\n",
    "       drawMaskRcnnHelperFunction(frameCopy,poseIndex,frame_rcnnbboxes,\n",
    "                       frame_teamColors,frame_actions,\n",
    "                       frame_rois,frame_masks)\n",
    "       DrawPose.drawBall(frameCopy,w,h,ball_position,(255,0,0),20)\n",
    "    #END GAZE DETECTION tag1\n",
    "\n",
    "    #Tracker\n",
    "\n",
    "    if len(list(Tracker.previousFramePose.keys())) != 0 :\n",
    "        #actions = [[f] for f in frame_actions]\n",
    "        finalActionClasses = Tracker.updatePosesClasses(posenetPredCombined,\n",
    "                                                  frame_actions,\n",
    "                                                  frame_posenetbboxs,\n",
    "                                                  frameCopy.shape[0],frameCopy.shape[1])\n",
    "\n",
    "\n",
    "    Tracker.setPrevFrameWrapper(frame_posenetbboxs,posenetPredCombined,\n",
    "                                                frame_actions,\n",
    "                                                frameCopy.shape[0],frameCopy.shape[1])\n",
    "    #End Tracker\n",
    "\n",
    "    #Drawing boxes and ball\n",
    "    if len(frame_bboxs):\n",
    "       drawMaskRcnnHelperFunction(frameCopy,poseIndex,frame_rcnnbboxes,\n",
    "                                   frame_teamColors,finalActionClasses,\n",
    "                                   frame_rois,frame_masks)\n",
    "       DrawPose.drawBall(frameCopy,w,h,ball_position,(255,0,0),20)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    return frameCopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializeModels():\n",
    "    loadMaskRcnn()\n",
    "    ActionClassificationCosine.loadPosenetModel()\n",
    "    args['knnLearner'] = getLearner(3)\n",
    "def proccessFrame(frame):\n",
    "    global counter\n",
    "    if args['net'] == None:\n",
    "        initializeModels()\n",
    "    if counter%1 == 0:\n",
    "        outFrame = detectVideos(frame)\n",
    "    counter += 1\n",
    "    return outFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:   0%|          | 0/86 [00:00<?, ?it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:20\n",
      "Moviepy - Building video /Users/sandeep/Desktop/dataandmodles/data/videotest/input1__out_ball.mp4.\n",
      "Moviepy - Writing video /Users/sandeep/Desktop/dataandmodles/data/videotest/input1__out_ball.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:   2%|▏         | 2/86 [00:11<08:10,  5.84s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:   3%|▎         | 3/86 [00:22<10:10,  7.35s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:   5%|▍         | 4/86 [00:33<11:25,  8.36s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:   6%|▌         | 5/86 [00:45<12:40,  9.39s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:   7%|▋         | 6/86 [00:57<13:36, 10.20s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:   8%|▊         | 7/86 [01:08<13:44, 10.43s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:   9%|▉         | 8/86 [01:19<14:02, 10.80s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  10%|█         | 9/86 [01:31<14:12, 11.08s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  12%|█▏        | 10/86 [01:43<14:33, 11.49s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  13%|█▎        | 11/86 [01:55<14:27, 11.57s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  14%|█▍        | 12/86 [02:07<14:14, 11.54s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  15%|█▌        | 13/86 [02:20<14:37, 12.02s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  16%|█▋        | 14/86 [02:31<14:09, 11.80s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  17%|█▋        | 15/86 [02:44<14:17, 12.08s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  19%|█▊        | 16/86 [02:56<14:12, 12.18s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  20%|█▉        | 17/86 [03:08<13:59, 12.17s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  21%|██        | 18/86 [03:21<13:56, 12.30s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  22%|██▏       | 19/86 [03:32<13:18, 11.91s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  23%|██▎       | 20/86 [03:44<12:58, 11.80s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  24%|██▍       | 21/86 [03:57<13:14, 12.23s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  26%|██▌       | 22/86 [04:09<12:54, 12.10s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  27%|██▋       | 23/86 [04:20<12:30, 11.91s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  28%|██▊       | 24/86 [04:31<12:06, 11.73s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  29%|██▉       | 25/86 [04:45<12:27, 12.25s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  30%|███       | 26/86 [04:58<12:23, 12.39s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  31%|███▏      | 27/86 [05:09<11:58, 12.19s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  33%|███▎      | 28/86 [05:21<11:39, 12.06s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  34%|███▎      | 29/86 [05:32<11:16, 11.87s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  35%|███▍      | 30/86 [05:43<10:47, 11.57s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  36%|███▌      | 31/86 [05:55<10:45, 11.73s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  37%|███▋      | 32/86 [06:07<10:25, 11.57s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  38%|███▊      | 33/86 [06:19<10:31, 11.92s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  40%|███▉      | 34/86 [06:34<10:54, 12.59s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  41%|████      | 35/86 [06:46<10:33, 12.43s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  42%|████▏     | 36/86 [06:58<10:15, 12.32s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  43%|████▎     | 37/86 [07:09<09:49, 12.03s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  44%|████▍     | 38/86 [07:20<09:28, 11.85s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  45%|████▌     | 39/86 [07:32<09:11, 11.73s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  47%|████▋     | 40/86 [07:46<09:32, 12.45s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  48%|████▊     | 41/86 [07:58<09:19, 12.43s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  49%|████▉     | 42/86 [08:08<08:26, 11.50s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  50%|█████     | 43/86 [08:18<08:05, 11.29s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  51%|█████     | 44/86 [08:28<07:31, 10.74s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  52%|█████▏    | 45/86 [08:40<07:38, 11.19s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  53%|█████▎    | 46/86 [08:53<07:46, 11.67s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  55%|█████▍    | 47/86 [09:04<07:31, 11.57s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  56%|█████▌    | 48/86 [09:14<07:03, 11.14s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  57%|█████▋    | 49/86 [09:27<07:06, 11.53s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  58%|█████▊    | 50/86 [09:39<07:05, 11.81s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  59%|█████▉    | 51/86 [09:51<06:50, 11.74s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  60%|██████    | 52/86 [10:04<06:51, 12.12s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  62%|██████▏   | 53/86 [10:17<06:50, 12.44s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  63%|██████▎   | 54/86 [10:30<06:45, 12.68s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  64%|██████▍   | 55/86 [10:42<06:20, 12.26s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  65%|██████▌   | 56/86 [10:54<06:11, 12.39s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  66%|██████▋   | 57/86 [11:06<05:56, 12.30s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  67%|██████▋   | 58/86 [11:18<05:42, 12.22s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  69%|██████▊   | 59/86 [11:32<05:42, 12.67s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  70%|██████▉   | 60/86 [11:43<05:17, 12.22s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  71%|███████   | 61/86 [11:55<05:01, 12.06s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  72%|███████▏  | 62/86 [12:07<04:50, 12.12s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  73%|███████▎  | 63/86 [12:18<04:31, 11.81s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  74%|███████▍  | 64/86 [12:30<04:19, 11.82s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  76%|███████▌  | 65/86 [12:42<04:09, 11.90s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  77%|███████▋  | 66/86 [12:53<03:52, 11.63s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  78%|███████▊  | 67/86 [13:04<03:33, 11.24s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  79%|███████▉  | 68/86 [13:13<03:09, 10.53s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  80%|████████  | 69/86 [13:24<03:03, 10.79s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  81%|████████▏ | 70/86 [13:34<02:51, 10.71s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  83%|████████▎ | 71/86 [13:45<02:40, 10.73s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  84%|████████▎ | 72/86 [13:57<02:33, 10.95s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  85%|████████▍ | 73/86 [14:07<02:20, 10.82s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  86%|████████▌ | 74/86 [14:17<02:05, 10.46s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  87%|████████▋ | 75/86 [14:27<01:55, 10.46s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  88%|████████▊ | 76/86 [14:38<01:46, 10.63s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  90%|████████▉ | 77/86 [14:49<01:34, 10.52s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  91%|█████████ | 78/86 [15:00<01:25, 10.69s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  92%|█████████▏| 79/86 [15:10<01:13, 10.51s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  93%|█████████▎| 80/86 [15:20<01:03, 10.52s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  94%|█████████▍| 81/86 [15:31<00:53, 10.62s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  95%|█████████▌| 82/86 [15:44<00:44, 11.23s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  97%|█████████▋| 83/86 [15:54<00:32, 11.00s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  98%|█████████▊| 84/86 [16:04<00:21, 10.54s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  99%|█████████▉| 85/86 [16:13<00:10, 10.16s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t: 100%|██████████| 86/86 [16:23<00:00, 10.03s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initalized general line:17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /Users/sandeep/Desktop/dataandmodles/data/videotest/input1__out_ball.mp4\n",
      "CPU times: user 41min 39s, sys: 1min 33s, total: 43min 12s\n",
      "Wall time: 16min 34s\n"
     ]
    }
   ],
   "source": [
    "inputPath  = '/Users/sandeep/Desktop/dataandmodles/data/videotest/input1.mov'\n",
    "outputPath = '/Users/sandeep/Desktop/dataandmodles/data/videotest/input1__out_ball.mp4'\n",
    "counter = 0\n",
    "\n",
    "clip1 = VideoFileClip(inputPath)\n",
    "outClip1 = clip1.fl_image(proccessFrame)\n",
    "%time  outClip1.write_videofile(outputPath,audio=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#Visual Debugger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "TESTARGS = {\n",
    "            'debugger' : False,\n",
    "            'testImage1' : '/Users/sandeep/Desktop/dataandmodles/data/pz3Pointer.png',\n",
    "            'testResultPath' : '/Users/sandeep/Desktop/dataandmodles/data/weightedDistanceAndTeamDetection'\n",
    "           }\n",
    "import DrawPose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def load_image():\n",
    "    img = cv2.imread(TESTARGS['testImage1'])\n",
    "    return img, img.shape[0] , img.shape[1]\n",
    "\n",
    "def write_image(img,fileName):\n",
    "    cv2.imwrite(f'{TESTARGS[\"testResultPath\"]}/{fileName}.png' , img)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def getLargerBbox(imgh,imgw,left,top,right,bottom):\n",
    "    n = 10\n",
    "    left,top = (left-n,top-n) #left_top (w,h)/ (col,row)\n",
    "    right,bottom = (right+n ,bottom+n ) #right_bottom\n",
    "    #Applying boundary condition\n",
    "    left,top = max(0,left) , max(0,top) \n",
    "    right,bottom =  min(right,imgw) , min(bottom,imgh) \n",
    "    return left,top,right,bottom\n",
    "\n",
    "    \n",
    "def roiBackgroundSubtraction(mask,roi,h,w,left,top,right,bottom):\n",
    "    #TEST PASSEDf\n",
    "    empty_image = np.zeros((h,w,3))\n",
    "    empty_image[top:bottom, left:right][mask] = roi\n",
    "    return empty_image\n",
    "\n",
    "def cropRoi(img,left,top,right,bottom):\n",
    "    roiCropped = ActionClassificationCosine.cropRoi(img,top,left,bottom,right)\n",
    "    return roiCropped\n",
    "\n",
    "def resizeRoi(img):\n",
    "    img = imutils.resize(img , width=244)\n",
    "    return img\n",
    "\n",
    "def transformRoi(mask,roi,img,h,w,left,top,right,bottom):\n",
    "    finalRoi = cropRoi(img,left,top,right,bottom)\n",
    "    finalRoi = resizeRoi(finalRoi)\n",
    "    return finalRoi\n",
    "\n",
    "def transformRoiBoka(mask,roi,img,h,w,left,top,right,bottom):\n",
    "    blurredImg = np.array(cv2.bilateralFilter(img,9,75,75))\n",
    "    blurredImg[top:bottom, left:right][mask] = roi\n",
    "    left,top,right,bottom = getLargerBbox(h,w,left,top,right,bottom)\n",
    "    roiCropped = cropRoi(blurredImg,left,top,right,bottom)\n",
    "    roi = resizeRoi(roiCropped)\n",
    "    #TODO: originally it only returned roi\n",
    "    return roi,roiCropped,left,top,right,bottom\n",
    "\n",
    "\n",
    "def drawPose(resizedRoi):\n",
    "    poses,boxes = ActionClassificationCosine.getPoses(resizedRoi)\n",
    "    resizedRoiWithPose = DrawPose.draw_skel_and_kp(poses,resizedRoi,(255,0,255))\n",
    "    return resizedRoiWithPose\n",
    "\n",
    "def getActionClass(resizedRoi):\n",
    "    poses,boxes = ActionClassificationCosine.getPoses(resizedRoi)\n",
    "    posesCopy = copy.deepcopy(poses)\n",
    "    if len(boxes['bbox']):\n",
    "        classes = ActionClassificationCosine.fit(poses,boxes,resizedRoi.shape[0] ,\n",
    "                                                 resizedRoi.shape[1])\n",
    "    else:\n",
    "        classes = [['unknown']]\n",
    "    return classes[0][0],posesCopy,boxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Getting Coordinates from cropped to main image \n",
    "def getScaleFactors(imgW, imgH, originalImgH , originalImgW):\n",
    "    '''\n",
    "\n",
    "       Helper function for get_data()\n",
    "       Parameter\n",
    "       -----------\n",
    "       imgW , imgH : dimensions of the  image where the coords needs to go to\n",
    "       originalImgH , originalImgW : dimensions of the  image where the coords needs to go from\n",
    "       Returns a tensor with given scalefactor (wdith,height). \n",
    "    '''\n",
    "    scale = (imgW/originalImgW,imgH/originalImgH);\n",
    "    return scale\n",
    "\n",
    "def mapCoord(coord,scaleFactors):\n",
    "    '''\n",
    "      Helper function for get_data()\n",
    "      Parameter\n",
    "      ---------\n",
    "      coord : a tuple  cotaining the coordinates \n",
    "      \n",
    "      scaleFactors : a tuple containing scaleFactors \n",
    "      \n",
    "      Return\n",
    "      -------\n",
    "      coord : A tuple of coordinate in integer scaled by their scaleFactors respectively\n",
    "    '''\n",
    "    coordInOriginalImage = [int(coord[0] * scaleFactors[0]) , int(coord[1] * scaleFactors[1])]\n",
    "    return tuple(coordInOriginalImage)\n",
    "\n",
    "def mapCoordToCroppedImage(keypointPosition,scaleFactor):\n",
    "    '''\n",
    "    Parameter\n",
    "    ----------\n",
    "    keypointPosition : A list containing dictionary of key points for a human \n",
    "    Example {'x': 598, 'y': 509} \n",
    "    \n",
    "    imgH : Number of rows\n",
    "    \n",
    "    imgW : Number of cols \n",
    "    \n",
    "    Return\n",
    "    -----------\n",
    "    keypointPosition : A list containing dictionary of key points for a human.\n",
    "    The coords are relatvie to the square image of size (244*244)\n",
    "    \n",
    "    '''\n",
    "    coord =  mapCoord(list(keypointPosition.values()),scaleFactor)\n",
    "    #coords (row,col)\n",
    "    keypointPosition['x'] = coord[0]\n",
    "    keypointPosition['y'] = coord[1]\n",
    "    \n",
    "    return keypointPosition\n",
    "\n",
    "def mapKeypointsPosition(pose,enlargedCroppedH,enlargedCroppedW,croppedH,croppedW):\n",
    "    '''\n",
    "    Helper function of mapPosesToCroppedImage\n",
    "    '''\n",
    "    scaleFactor = getScaleFactors(croppedW,croppedH,enlargedCroppedH, enlargedCroppedW)\n",
    "    for keypoint in pose['keypoints']:\n",
    "        keyPointPosition = mapCoordToCroppedImage(keypoint['position'],scaleFactor)\n",
    "        keypoint['position'] = keyPointPosition\n",
    "    return pose\n",
    "\n",
    "def mapPosesToCroppedImage(posenetPred,enlargedCroppedH,enlargedCroppedW,croppedH,croppedW):\n",
    "    '''\n",
    "    This functions maps the posenetPred keypoints to the original cropped image \n",
    "    '''\n",
    "    for index,pose in enumerate(posenetPred['detectionList']):\n",
    "        pose = mapKeypointsPosition(pose,enlargedCroppedH,enlargedCroppedW,croppedH,croppedW)\n",
    "        posenetPred['detectionList'][index] = pose\n",
    "    return posenetPred\n",
    "\n",
    "\n",
    "def mapKeypointsPositionToMainImage(pose,top,left):\n",
    "    '''\n",
    "    Helper function of mapPosesToMainImage\n",
    "    '''\n",
    "    for keypoint in pose['keypoints']:\n",
    "        keypoint['position']['x'] =  keypoint['position']['x'] + left\n",
    "        keypoint['position']['y'] =  keypoint['position']['y'] + top\n",
    "    return pose\n",
    "def mapPosesToMainImage(posenetPred,top,left):\n",
    "    '''\n",
    "    This function takes posenetPred where keypoints coords are relative to the original \n",
    "    cropped image \n",
    "    '''\n",
    "    for index,pose in enumerate(posenetPred['detectionList']):\n",
    "        pose = mapKeypointsPositionToMainImage(pose,top,left)\n",
    "        posenetPred['detectionList'][index] = pose\n",
    "    return posenetPred  \n",
    "\n",
    "def mapPosesToMainImageWrapper(posenetPred,topLarger, leftLarger,resizedRoi,roiCropped):\n",
    "    '''\n",
    "    This function is a wrapper function that maps raw posenetPred for cropped images to poses \n",
    "    in the full image. \n",
    "    Used for gaze detection.\n",
    "    '''\n",
    "    posenetPred = mapPosesToCroppedImage(posenetPred,\n",
    "                                         resizedRoi.shape[0], resizedRoi.shape[1],\n",
    "                                         roiCropped.shape[0],roiCropped.shape[1])\n",
    "    posenetPred = mapPosesToMainImage(posenetPred,topLarger,leftLarger)\n",
    "    return posenetPred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Tracker \n",
    "def tracker(frame,poses,bboxes,classes,prevFrameMidpoints):\n",
    "        \n",
    "    cv2.imshow('test', frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def drawMaskRcnnHelperFunction(frameCopy,poseIndex,frame_rcnnbboxes,\n",
    "                               frame_teamColors,frame_actions,frame_rois,frame_masks):\n",
    "    for index,bbox in enumerate(frame_rcnnbboxes):\n",
    "        if index != poseIndex:\n",
    "            color = frame_teamColors[index]\n",
    "        else:\n",
    "            color = (255,0,255)\n",
    "        DrawPose.drawPred(frameCopy,\n",
    "                          frame_actions[index],\n",
    "                          1.0,\n",
    "                          bbox[0],bbox[1], bbox[2], bbox[3], \n",
    "                          color,\n",
    "                          yolo=False,\n",
    "                          roi=frame_rois[index],\n",
    "                          mask=frame_masks[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def visualDebugger():\n",
    "    loadMaskRcnn()\n",
    "    #ActionClassificationCosine.loadPosenetModel()\n",
    "    rawFrame=[]\n",
    "    learner = getLearner(3)\n",
    "    net = args['net']\n",
    "    output_layer_names = args['output_layer_names']\n",
    "    \n",
    "    frame,h,w = load_image()\n",
    "    frameCopy = frame[:]\n",
    "    frameCopy2 = frame[:]\n",
    "    \n",
    "    \n",
    "    \n",
    "    classIDs,confidences,boxes,masks = fitMaskRcnn(frame)\n",
    "    \n",
    "    #Gaze detection variable\n",
    "    posenetPredCombined = {'detectionList':[]}\n",
    "    frame_bboxs = []\n",
    "    frame_actions = []\n",
    "    \n",
    "    #Drawing variables\n",
    "    frame_rois = []\n",
    "    frame_masks = []\n",
    "    frame_rcnnbboxes = []\n",
    "    frame_teamColors = []\n",
    "    for detected_object in range(0, len(boxes)):\n",
    "        \n",
    "        left,top,width,height,mask = getBoxesAndMask(boxes, masks, detected_object)\n",
    "\n",
    "        bboxFit = check_bbox_size(width,height, *frame.shape[0:-1])\n",
    "        labelFit = check_label(classIDs[detected_object])\n",
    "        if bboxFit and labelFit and left>0:\n",
    "            #uncommet to use basic fast rcnn and remove hsv from teamName\n",
    "            #team,roi= detectTeam(frameCopy, left ,top, left+width,top+height , algo='basic',mask=mask)\n",
    "            team,hsv,roi= (detectTeam(frameCopy, left ,top, left+width,top+height , algo='kmeans',\n",
    "                                     learner=learner\n",
    "                                     ,mask=mask))\n",
    "            \n",
    "            teamColor, teamName = getTeamInfo(team)\n",
    "            teamName = f'{team},{hsv}'\n",
    "            \n",
    "            resizedRoi,roiCropped,leftLarger,topLarger,rightLarger,bottomLarger = transformRoiBoka(mask,\n",
    "                                                                                                  roi,frame,\n",
    "                                                                                                  h,w,left,top,\n",
    "                                                                                                  left+width,\n",
    "                                                                                                  top+height )\n",
    "            \n",
    "            start = time.time()\n",
    "            \n",
    "            \n",
    "            actionClass,posenetPred,_ = getActionClass(resizedRoi)\n",
    "            \n",
    "            \n",
    "            \n",
    "            #GAZE DETECTION PREP(Combine posenetPred for gaze detection):\n",
    "            \n",
    "            posenetPred = mapPosesToCroppedImage(posenetPred,\n",
    "                                                 resizedRoi.shape[0], resizedRoi.shape[1],\n",
    "                                                 roiCropped.shape[0],roiCropped.shape[1])\n",
    "\n",
    "\n",
    "            posenetPred = mapPosesToMainImage(posenetPred,topLarger,leftLarger)\n",
    "    \n",
    "           \n",
    "            for pose in posenetPred['detectionList']:\n",
    "                posenetPredCombined['detectionList'].append(pose)\n",
    "            if len(posenetPred['detectionList']) != 0:\n",
    "                frame_bboxs.append([leftLarger,topLarger,rightLarger,bottomLarger])\n",
    "                frame_actions.append(actionClass)\n",
    "                frame_masks.append(mask)\n",
    "                frame_rois.append(roi)\n",
    "                frame_rcnnbboxes.append([left ,top, left+width,top+height])\n",
    "                frame_teamColors.append(teamColor)\n",
    "            #END GAZE DETECTION PREP:\n",
    "            end = time.time()\n",
    "            print(actionClass)\n",
    "            print(round(end-start,3))\n",
    "    \n",
    "           \n",
    "    #Gaze Module\n",
    "    if len(frame_bboxs):\n",
    "       ball_position,poseIndex = GazeModule.fitGazeModule(posenetPredCombined,frame_bboxs,frame_actions)\n",
    "       drawMaskRcnnHelperFunction(frameCopy,poseIndex,frame_rcnnbboxes,\n",
    "                       frame_teamColors,frame_actions,\n",
    "                       frame_rois,frame_masks)\n",
    "       DrawPose.drawBall(frameCopy,w,h,ball_position,(255,0,0),20)\n",
    "    \n",
    "    write_image(frameCopy, f'GazeModlueOutPut')\n",
    "\n",
    "    #Posenet On the whole image \n",
    "    print('All test images saved')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#visualDebugger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

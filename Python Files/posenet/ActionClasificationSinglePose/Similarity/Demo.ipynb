{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import sys \n",
    "import random\n",
    "import json\n",
    "import cv2 \n",
    "import base64\n",
    "import requests as req\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "from io import BytesIO  \n",
    "%matplotlib inline\n",
    "import sklearn.metrics.pairwise as pairwise\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Importing ActionClassificationCosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weightedDistanceMatching(poseVector1,poseVector2):\n",
    "    '''\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    (poseVector1 : a 2D list pose vector of a human + theta [[poseVec],[thetaVector]]\n",
    "    theta : weigths for human pose vector\n",
    "    Example theta = [w_0x , w_0y.........w_17x, w_17y])\n",
    "    or \n",
    "    (poseVector1 : a 1D list pose vector of a human, used for building tree. \n",
    "    theta : A list with of ones. \n",
    "    Example [1,1,.....1] (17x1) )\n",
    "    \n",
    "    poseVector2 : pose vector that is to be compared with the human\n",
    "    \n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    ------------\n",
    "    weigtheDistance  : \n",
    "    '''\n",
    "    poseVector1 = np.array(poseVector1) \n",
    "    if poseVector1.shape[0] == 36:\n",
    "        poseVector1 = poseVector1.reshape(1,-1)\n",
    "        theta = np.ones_like(poseVector1)\n",
    "    elif poseVector1.shape[0] == 72:\n",
    "        poseVector1 = poseVector1.reshape(2,36)\n",
    "        theta = poseVector1[1]\n",
    "        poseVector1 = poseVector1[0]\n",
    "    \n",
    "    poseVector2 = np.array(poseVector2).reshape(1,-1)\n",
    "    term1 = 1/ np.sum(theta)\n",
    "    #Finding term 2\n",
    "    distanceTranspose = np.absolute(poseVector1 - poseVector2).transpose()\n",
    "    term2 = np.matmul(theta,distanceTranspose)\n",
    "\n",
    "        \n",
    "    \n",
    "    return term1 * term2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosineDistanceMatching(poseVector1,poseVector2):\n",
    "    '''\n",
    "    Returns the cosine similarity as a distance function between the two L2 normalized vectors.\n",
    "    The distance is inversely porportional to the similarity between the two vectors\n",
    "    '''\n",
    "    poseVector1 , poseVector2 = np.array(poseVector1).reshape(1,-1) , np.array(poseVector2).reshape(1,-1)\n",
    "    cosineDistance = pairwise.cosine_distances(poseVector1 , poseVector2) \n",
    "    distance = np.sqrt(cosineDistance * 2)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from ActionClassificationCosine.ipynb\n",
      "importing Jupyter notebook from ActionClassificationCosineDatasetGen.ipynb\n",
      "Loading Poses Data....\n",
      "Initializing VPTREE....\n",
      "VPTREE Ready To Use....\n",
      "importing Jupyter notebook from SinglePlayerPoseDatasetGen.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "import ActionClassificationCosine "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Setting constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#constants\n",
    "PART_NAMES = [\n",
    "    \"nose\", \"leftEye\", \"rightEye\", \"leftEar\", \"rightEar\", \"leftShoulder\",\n",
    "    \"rightShoulder\", \"leftElbow\", \"rightElbow\", \"leftWrist\", \"rightWrist\",\n",
    "    \"leftHip\", \"rightHip\", \"leftKnee\", \"rightKnee\", \"leftAnkle\", \"rightAnkle\"\n",
    "]\n",
    "PART_IDS = {pn: pid for pid, pn in enumerate(PART_NAMES)} ;PART_IDS\n",
    "CONNECTED_PART_NAMES = [\n",
    "    (\"leftHip\", \"leftShoulder\"), (\"leftElbow\", \"leftShoulder\"),\n",
    "    (\"leftElbow\", \"leftWrist\"), (\"leftHip\", \"leftKnee\"),\n",
    "    (\"leftKnee\", \"leftAnkle\"), (\"rightHip\", \"rightShoulder\"),\n",
    "    (\"rightElbow\", \"rightShoulder\"), (\"rightElbow\", \"rightWrist\"),\n",
    "    (\"rightHip\", \"rightKnee\"), (\"rightKnee\", \"rightAnkle\"),\n",
    "    (\"leftShoulder\", \"rightShoulder\"), (\"leftHip\", \"rightHip\")\n",
    "]\n",
    "\n",
    "CONNECTED_PART_INDICES = [(PART_IDS[a], PART_IDS[b]) for a, b in CONNECTED_PART_NAMES];\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adjacent_keypoints(keypoints):\n",
    "    '''\n",
    "    Helper function of draw_skel_and _kp\n",
    "    Returns 2 coord of 2 points where line needs to be drawn\n",
    "    EXAMPLE: [[X1,Y1],[X2,Y2]]\n",
    "    '''\n",
    "    results = []\n",
    "    for left, right in CONNECTED_PART_INDICES:\n",
    "       results.append(\n",
    "           np.array([\n",
    "                [ keypoints[left]['position']['x'] , keypoints[left]['position']['y'] ],\n",
    "                [ keypoints[right]['position']['x'] , keypoints[right]['position']['y'] ]\n",
    "                    ]\n",
    "           ).astype(np.int32)\n",
    "        )\n",
    "    return results\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToBase64(image):\n",
    "    retval, buffer = cv2.imencode('.jpg', image)\n",
    "    my_string = base64.b64encode(buffer)\n",
    "    my_string = my_string.decode('utf-8')\n",
    "    return my_string\n",
    "\n",
    "#Sending data to server\n",
    "def getPoses(image):\n",
    "    image = cv2.cvtColor(image , cv2.COLOR_BGR2RGB)\n",
    "    image_string = convertToBase64(image)\n",
    "    url2 = 'http://localhost:3000/postImage'\n",
    "    data = {'imgBase64':'data:image/png;base64,'+image_string}\n",
    "    r = req.post(url=url2 , data = data)\n",
    "    poses = r.json()\n",
    "    \n",
    "    url2 = 'http://localhost:3000/getBBox'\n",
    "    r = req.post(url=url2)\n",
    "    bboxes = r.json()\n",
    "    return poses,bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_keypoints(poses,img):\n",
    "    cv_keypoints= []\n",
    "    for pose in poses['detectionList']:\n",
    "        keypoints = pose['keypoints']\n",
    "        for keypoint in keypoints:\n",
    "            x,y,score = round(keypoint['position']['x']) ,round(keypoint['position']['y']),keypoint['score']\n",
    "            cv_keypoints.append(cv2.KeyPoint(x,y , 10. *score))\n",
    "    out_img = cv2.drawKeypoints(img, cv_keypoints , outImage=np.array([]) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_skelton(poses,img):\n",
    "    '''\n",
    "    This function is not used anywhere. \n",
    "    Written to demonstrate how skelton can be drawn\n",
    "    '''\n",
    "    adjacent_keypoints = []\n",
    "    out_img = img\n",
    "    for pose in poses['detectionList']:\n",
    "        keypoints  = pose['keypoints']\n",
    "        new_keypoints = get_adjacent_keypoints(keypoints)\n",
    "        adjacent_keypoints.extend(new_keypoints)\n",
    "    out_img = cv2.polylines(out_img , adjacent_keypoints, isClosed=False, color=(255,255,0))\n",
    "    return out_img    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_skel_and_kp(poses , img, color,classes):\n",
    "    out_img = img\n",
    "    adjacent_keypoints = []\n",
    "    cv_keypoints = []\n",
    "    #For every pose of the player\n",
    "    for i,pose in enumerate(poses['detectionList']):\n",
    "        keypoints = pose['keypoints']\n",
    "        new_keypoint = get_adjacent_keypoints(keypoints)\n",
    "        adjacent_keypoints.extend(new_keypoint)\n",
    "        \n",
    "        for keypoint in keypoints:\n",
    "            x,y,score = round(keypoint['position']['x']) ,round(keypoint['position']['y']),keypoint['score']\n",
    "            cv_keypoints.append(cv2.KeyPoint(x,y , 10. * score))\n",
    "        cv2.putText(out_img, classes[i][0], (x,y), cv2.FONT_ITALIC, 0.6, (0, 255, 0), 1)\n",
    "    \n",
    "    out_img = cv2.drawKeypoints(\n",
    "        img, cv_keypoints , outImage=np.array([]), color=color,\n",
    "        flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS )\n",
    "    out_img = cv2.polylines(out_img , adjacent_keypoints , isClosed=False, color=list(color))\n",
    "    return out_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Sending to server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading model\n",
    "r = req.get(url='http://localhost:3000/loadModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1239.0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "700*1.77"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posenet Time:0.405\n",
      "Posenet Time:0.422\n",
      "Posenet Time:0.419\n",
      "Posenet Time:0.391\n",
      "Posenet Time:0.349\n",
      "VPN Time:0.55\n",
      "Drawing Time:0.001\n",
      "Posenet Time:0.369\n",
      "VPN Time:0.401\n",
      "Drawing Time:0.001\n",
      "Posenet Time:0.354\n",
      "VPN Time:0.477\n",
      "Drawing Time:0.002\n",
      "Posenet Time:0.357\n",
      "VPN Time:0.515\n",
      "Drawing Time:0.002\n",
      "Posenet Time:0.359\n",
      "VPN Time:0.365\n",
      "Drawing Time:0.001\n",
      "Posenet Time:0.361\n",
      "VPN Time:0.474\n",
      "Drawing Time:0.002\n",
      "Posenet Time:0.364\n",
      "VPN Time:0.605\n",
      "Drawing Time:0.001\n",
      "Posenet Time:0.341\n",
      "VPN Time:0.532\n",
      "Drawing Time:0.002\n",
      "Posenet Time:0.362\n",
      "VPN Time:0.237\n",
      "Drawing Time:0.001\n",
      "Posenet Time:0.365\n",
      "VPN Time:0.26\n",
      "Drawing Time:0.001\n",
      "Posenet Time:0.362\n",
      "VPN Time:0.245\n",
      "Drawing Time:0.001\n",
      "Posenet Time:0.357\n",
      "VPN Time:0.214\n",
      "Drawing Time:0.001\n"
     ]
    }
   ],
   "source": [
    "videoPath ='/Users/sandeep/Desktop/dataandmodles/data/unzoomed.mov'\n",
    "cap = cv2.VideoCapture(videoPath)\n",
    "count = 0\n",
    "while cap.isOpened():\n",
    "    ret,frame = cap.read()\n",
    "    if ret :\n",
    "        #do stuff\n",
    "        start = time.time()\n",
    "        poses,bboxes = getPoses(frame)\n",
    "        end = time.time()\n",
    "        print(f'Posenet Time:{round(end-start,3)}')\n",
    "        \n",
    "        if len(bboxes['bbox']) != 0:\n",
    "            posesCopy = copy.deepcopy(poses)\n",
    "        \n",
    "            #frame = draw_visibilty_cone(poses,frame)\n",
    "            start = time.time()\n",
    "            classes = ActionClassificationCosine.fit(poses,\n",
    "                                                     bboxes,\n",
    "                                                     inputImgH=frame.shape[0],\n",
    "                                                     inputImgW=frame.shape[1])\n",
    "            end = time.time()\n",
    "            print(f'VPN Time:{round(end-start,3)}')\n",
    "\n",
    "            start = time.time()\n",
    "\n",
    "            frame = draw_skel_and_kp(posesCopy,frame,[255,0,0],classes)\n",
    "            end = time.time()\n",
    "            print(f'Drawing Time:{round(end-start,3)}')\n",
    "#         End of do stuff\n",
    "        cv2.imshow('test', frame)\n",
    "        #cv2.imwrite(f\"/Users/sandeep/Desktop/dataandmodles/data/coneVision/{count}.png\" , frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break  \n",
    "            \n",
    "    else:\n",
    "        cap.release()\n",
    "        break\n",
    "    count += 1\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bbox': [[{'x': 703.3642535886137, 'y': 224.86874854275925},\n",
       "   {'x': 1040.8136556552768, 'y': 224.86874854275925},\n",
       "   {'x': 1040.8136556552768, 'y': 961.0684908467592},\n",
       "   {'x': 703.3642535886137, 'y': 961.0684908467592}]]}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-16c183f2b6dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": [
    "b = a.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['a'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "from sklearn import preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw =  {10:'left_ankel' , 13:'right_ankel' , 9:'left_knee',12:'right_knee',8:'left_hip',\n",
    "        11:'right_hip', 4:'left_wrist',7:'right_wrist', 3:'left_elbow',6:'right_elbow',\n",
    "        2:'left_shoulder',5:'right_shoulder',1:'nose',17:'right_ear',15:'right_eye',\n",
    "        14:'left_eye' , 16:'left_ear', 0:'unknown'}\n",
    "\n",
    "sorted_keys = np.sort((np.array(list(raw.keys()))))\n",
    "PART_IDS = {raw[i]:i for i in sorted_keys}\n",
    "\n",
    "CONNECTED_PART_NAMES = [\n",
    "    (\"left_hip\", \"right_hip\"), (\"left_elbow\", \"left_shoulder\"),\n",
    "    (\"left_elbow\", \"left_wrist\"), (\"left_hip\", \"left_knee\"),\n",
    "    (\"left_knee\", \"left_ankel\"), (\"right_hip\", \"right_shoulder\"),\n",
    "    (\"right_elbow\", \"right_shoulder\"), (\"right_elbow\", \"right_wrist\"),\n",
    "    (\"right_hip\", \"right_knee\"), (\"right_knee\", \"right_ankel\"),\n",
    "    (\"left_shoulder\", \"right_shoulder\"), (\"left_hip\", \"left_shoulder\")\n",
    "]\n",
    "CONNECTED_PART_INDICES = [(PART_IDS[a], PART_IDS[b]) for a, b in CONNECTED_PART_NAMES];\n",
    "\n",
    "UNCONNECTED_PART_NAMES = [\"nose\", \"right_ear\" , \"left_ear\", \"right_eye\" , \"left_eye\",  \"unknown\"]\n",
    "UNCONNECTED_PART_INDICES = [PART_IDS[a] for a in UNCONNECTED_PART_NAMES];\n",
    "\n",
    "ARGS = {'normDatasetPath':'/Users/sandeep/Desktop/dataandmodles/data/singlePlayersPosesL2Normalized.csv',\n",
    "        'datasetPath':'/Users/sandeep/Desktop/dataandmodles/data/singlePlayersPoses.csv',\n",
    "        'datasetGen':False}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Handling Main Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 18)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(PART_NAMES), len(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    with open('/Users/sandeep/Downloads/dataset/annotation_dict.json') as f:\n",
    "      data = json.load(f)\n",
    "    labels = {0 : \"block\", 1 : \"pass\", 2 : \"run\", \n",
    "              3: \"dribble\",4: \"shoot\",5 : \"ball in hand\", \n",
    "              6 : \"defense\", 7: \"pick\" , 8 : \"no_action\" ,\n",
    "              9: \"walk\" ,10: \"discard\"}\n",
    "    return data , labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ARGS['datasetGen']:\n",
    "    annotations , labels = load_data()\n",
    "def get_label(fileName):\n",
    "    label = annotations[fileName]\n",
    "    return labels[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    " def getScaleFactors(imgW, imgH, originalImgH , originalImgW):\n",
    "    '''\n",
    "       Helper function for get_data()\n",
    "       Returns a tensor with given scalefactor (wdith,height). \n",
    "    '''\n",
    "    return (imgW/originalImgW, imgH/originalImgH);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapToSquareImage(coord,scaleFactors):\n",
    "    '''\n",
    "      Helper function for get_data()\n",
    "      Returns coord (width, height)\n",
    "    '''\n",
    "    coordInOriginalImage = [int(coord[0] * scaleFactors[0]) , int(coord[1] * scaleFactors[1])]\n",
    "    return tuple(coordInOriginalImage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_extended_pose(pose):\n",
    "    '''\n",
    "    Helper function for get_data() and get_posenet_extended_pose()\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    pose : A dictionary containing 1 pose. The keys refer to bodyparts relative to the raw dict.\n",
    "    Example {0:(x,y), ....} \n",
    "    \n",
    "    Return\n",
    "    ---------\n",
    "    extended_pose : A dictionary containing x and y coord has it own key\n",
    "    Example {0_x: 1 ,0_y: 7 ....}  \n",
    "    '''\n",
    "    extended_pose = {}\n",
    "    for key,value in poses_dict.items():\n",
    "        #TO DO: scale the value before setting to the value\n",
    "        value = mapToSquareImage(value,scale)\n",
    "        extended_pose[f'{key}_x'] = value[0]\n",
    "        extended_pose[f'{key}_y'] = value[1]\n",
    "    extended_pose['label'] = label \n",
    "    return extended_pose\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    '''\n",
    "    Helper function for generate_dataset()\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    data : A 1D list contining dict of 16 poses gotton from 16 frames for a single player\n",
    "    Example [{0_x:1 , 0_y:2 , 1_x:67........,'label':'walk'] \n",
    "    The coordinates of the poses are raw coords for players in image of size (178, 128)\n",
    "    '''\n",
    "    fileName = os.listdir('/Users/sandeep/Downloads/dataset/examples')\n",
    "    fileName = [name for name in fileName if name[-1] != '4']\n",
    "    data = []\n",
    "    scale = getScaleFactors(244,244,176,128)\n",
    "    for name in fileName:\n",
    "        posePath = f'/Users/sandeep/Downloads/dataset/examples/{name}'\n",
    "        try:\n",
    "            poses_list,label = np.load(posePath,allow_pickle=True) , get_label(name[0:-4])\n",
    "            for poses_dict in poses_list:\n",
    "                extended_pose = get_extended_pose(pose_dict)\n",
    "                data.append(extended_pose)\n",
    "        except KeyError:\n",
    "            continue\n",
    "    return data   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keys(df_keys):\n",
    "    '''\n",
    "    Helper function for get_proxy_coord\n",
    "    Returns keys that the df columns name refers too. eg. 0_x -> 0 \n",
    "    '''\n",
    "    global df_cols_to_keys \n",
    "    return [df_cols_to_keys[key] for key in df_keys]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_connected_keys(key):\n",
    "    key_pair_tuple = [t for t in CONNECTED_PART_INDICES if key in t]\n",
    "    return [key1 if key1 != key else key2 for (key1,key2) in key_pair_tuple ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_keys(list1 , list2):\n",
    "    '''\n",
    "    Helper function for get_proxy_coord\n",
    "    Returns keys that are not in the list2\n",
    "    '''\n",
    "    return list(set(list1)-set(list2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_keys_to_df_key(key):\n",
    "    return f'{key}_x' , f'{key}_y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unconneted_proxy_coord(keys):\n",
    "    '''\n",
    "    Helper function for get_proxy_coord\n",
    "    '''\n",
    "    usable_unconnected_keys = filter_keys(UNCONNECTED_PART_INDICES , keys)\n",
    "    if len(usable_unconnected_keys) != 0:\n",
    "        key_x , key_y  = map_keys_to_df_key(usable_unconnected_keys[0])\n",
    "        return key_x , key_y\n",
    "    else:\n",
    "        return get_connected_proxy_coord(2,keys)#trace starts from right shoulder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_connected_proxy_coord(key,keys):\n",
    "    '''\n",
    "    Helper function for get_proxy_coord\n",
    "    '''\n",
    "    connected_keys_with_key = get_connected_keys(key)\n",
    "    usable_connected_keys = filter_keys(connected_keys_with_key,keys)\n",
    "    if  len(usable_connected_keys) != 0:#base-case, we know there is no pose with 1 points\n",
    "        key_x , key_y = map_keys_to_df_key(usable_connected_keys[0])\n",
    "        return key_x,key_y\n",
    "    else:\n",
    "       key_x, key_y = get_connected_proxy_coord(connected_keys_with_key[0],keys)\n",
    "       return key_x,  key_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_proxy_coord(row):\n",
    "    '''\n",
    "    Helper function to replace the NaN values/ the poses that are not visible using poxy poses\n",
    "    PARAMS key: the key that gets passed is eg.1_x\n",
    "    '''\n",
    "    global df_cols_to_keys \n",
    "    #df keys with nan\n",
    "    df_keys = [key for key in row[row.isnull()].index.tolist() if key[-1] != 'y'] \n",
    "    keys = get_keys(df_keys)\n",
    "    for key in keys:\n",
    "        if key in UNCONNECTED_PART_INDICES:#if the nan key is a  Unconnected part \n",
    "            key_x , key_y = get_unconneted_proxy_coord(keys)\n",
    "        else:#if the nan key is a  Connected part \n",
    "            key_x, key_y = get_connected_proxy_coord(key,keys)\n",
    "                \n",
    "        current_key_x , current_key_y = map_keys_to_df_key(key)\n",
    "        row[current_key_x] , row[current_key_y] = row[key_x] , row[key_y]\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_cols():\n",
    "    '''\n",
    "    Helper function for generate_dataset()\n",
    "    '''\n",
    "    cols = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
    "    a = []\n",
    "    for col in cols:\n",
    "        xCol = f'{col}_x'\n",
    "        yCol = f'{col}_y'   \n",
    "        a.append(xCol)\n",
    "        a.append(yCol)\n",
    "    a.append('label')\n",
    "    b = {}\n",
    "    for col in cols:\n",
    "        b[f'{col}_x'] = col\n",
    "        b[f'{col}_y'] = col\n",
    "\n",
    "    return a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillNaN(df):\n",
    "    '''\n",
    "    Helper function for generate_dataset()\n",
    "    Updates the NaN cells with proxy coords. \n",
    "    '''\n",
    "    return  df.apply(get_proxy_coord, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(data=None):\n",
    "    '''\n",
    "    1.This function will fill the missing bodypoints with proxy coords and\n",
    "      generate l2 normalized dataset from raw data\n",
    "    \n",
    "    2.Helper function for generate_data_posenet()\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : A list with extended_poses.\n",
    "    If data is not passed then you are aiming to generate the main pose dataset \n",
    "    Example : [{0_x:1, 0_y:1 ,17_y:NaN, 17_y:NaN} , {0_x:1, 0_y:1 ,16_y:NaN, 16_y:NaN} , {..}]\n",
    "    \n",
    "    Return\n",
    "    -------\n",
    "    normalized_data : A 2D array with normalized data \n",
    "    [[0_x, 0_y, 1_x, 1_y, .......17_y] , [......]]\n",
    "    '''\n",
    "    if ARGS['datasetGen']:\n",
    "        data = get_data()\n",
    "    df = pd.DataFrame(data)\n",
    "    df_cols,df_cols_to_keys = get_df_cols()\n",
    "    df = df[df_cols[:-1]]\n",
    "    df[:-1] = fillNaN(df])\n",
    "    normalized_data = preprocessing.normalize(df, axis=1)\n",
    "    return normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(norm=True):\n",
    "    if norm:\n",
    "        return pd.read_csv(ARGS['normDatasetPath'])\n",
    "    elif norm == False:\n",
    "        return pd.read_csv(ARGS['datasetPath'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Handeling Posenet Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def posenet_part_to_part(part):\n",
    "    '''\n",
    "    Helper function of get_posenet_extended_pose\n",
    "    '''\n",
    "    if 'ankle' in part:\n",
    "        part.replace('ankle' , 'ankel')\n",
    "    if 'right' in part: \n",
    "        return f'right_{part[5:].lower(0)}'\n",
    "    elif 'left' in part:\n",
    "        return f'left_{part[5:].lower(0)}'\n",
    "    return part\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_part_to_key(part):\n",
    "    '''\n",
    "    Helper function of get_posenet_extended_pose()\n",
    "    '''\n",
    "    for key, part in raw.items():\n",
    "        if part == search_age:\n",
    "            return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_posenet_extended_pose(pose):\n",
    "    '''\n",
    "    Helper function for generate generate_dataset()\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    pose : A list containing dictionary containing 1 pose. The keys refer to bodyparts relative to the posenet pred.\n",
    "    Example [{'score': 0.8984865546226501, 'part': 'nose', 'position': {'x': 741.3767104497117, 'y': 201.7590852932459}}...]\n",
    "    \n",
    "    Return\n",
    "    ---------\n",
    "    extended_pose : A dictionary containing x and y coord has it own key\n",
    "    Example {0_x: 1 ,0_y: 7 ....}  \n",
    "    '''\n",
    "    #Change keys\n",
    "    pose_dict = {}\n",
    "    for part_dict in pose:\n",
    "        part = posenet_part_to_part(part_dict['part']) \n",
    "        key = map_part_to_key(part)\n",
    "        pose_dict[key] = (pose['position']['x'] , pose['position']['y'])\n",
    "    extended_pose = get_extended_pose(pose_dict)\n",
    "    return extended_pose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_posenet(poses):\n",
    "    '''\n",
    "    This functions generates l2 normalized data form non-empty(Must have atleast 1 humans)\n",
    "    Posenet results\n",
    "    \n",
    "    Parameters\n",
    "    ---------\n",
    "    poses : The non-empty output of Posenet model\n",
    "    Example {'detectionList': [{keypoints:[{score: , part:.. ,position:..}]} , human2 , ....]\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    normalized_data : A 2D list with exte\n",
    "    '''\n",
    "    data = []\n",
    "    for human in poses['detectionList']:\n",
    "        for pose in human['keypoints']:\n",
    "            extended_pose = get_posenet_extended_pose(pose)\n",
    "            data.append(extended_pose)\n",
    "\n",
    "    normalized_data = generate_dataset(data=data).drop(['label'], axis=1)\n",
    "    return normalized_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = read_dataset(norm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0_x',\n",
       " '0_y',\n",
       " '1_x',\n",
       " '1_y',\n",
       " '2_x',\n",
       " '2_y',\n",
       " '3_x',\n",
       " '3_y',\n",
       " '4_x',\n",
       " '4_y',\n",
       " '5_x',\n",
       " '5_y',\n",
       " '6_x',\n",
       " '6_y',\n",
       " '7_x',\n",
       " '7_y',\n",
       " '8_x',\n",
       " '8_y',\n",
       " '9_x',\n",
       " '9_y',\n",
       " '10_x',\n",
       " '10_y',\n",
       " '11_x',\n",
       " '11_y',\n",
       " '12_x',\n",
       " '12_y',\n",
       " '13_x',\n",
       " '13_y',\n",
       " '14_x',\n",
       " '14_y',\n",
       " '15_x',\n",
       " '15_y',\n",
       " '16_x',\n",
       " '16_y',\n",
       " '17_x',\n",
       " '17_y',\n",
       " 'label']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a.to_csv('/Users/sandeep/Desktop/dataandmodles/data/singlePlayersPoses.csv', index=False)\n",
    "#df_normalized_df = pd.DataFrame(df_normalized, columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_normalized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_normalized_df.to_csv('/Users/sandeep/Desktop/dataandmodles/data/singlePlayersPosesL2Normalized.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

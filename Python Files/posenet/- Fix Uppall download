- Fix Uppall download
- Go through uppall tutorail on youtube
	-https://www.youtube.com/watch?v=0ioBpqDGOf0&t=190s(DONE)
	- https://www.youtube.com/watch?v=9aCyigaQ_W0&t=1468s
	- Simulator:
		- No such file or direc
		- Fixed: Downlaoded MAC ONLY UPPAAL
-----------------------
Learning For Tutorial 1
- To controlwhen to take a transition (to “fire” it), it is possible to have a guard and a synchronization.

- Channels/functions
	- declare:?
	- called:!
	- Once the function gets called, you have other set of function that can be called
		- Every new state: new set of functions
			- example of enabled transition/function?
				-continue_on_street: carOne -> lLane
				- functionNmae : object1 -> object2
	- The synchronization mechanism inUppaalis a hand-shaking synchronization
		- Two process take a transition at the same time,
			- one will have a! and the other a?

- Gurads 
	- Are like if statements for the transition
	-A guard is a condition on the variables 

Updating
	- When taking a transition, two actions are possible: assignment of variables or reset of clocks.
-------------------
Learing from tutorial 2 
	- Mutal exculsion: 1 recource dont get excessed by 2 entity same time
	- Selection
		- Randomized intialization of some variables in a range, whenever, edge is executed
			- i:int[3,5] : randomly set i to 3 and t inclusive (i is a local variable)
			- You can set a globalVariable = i, thus, generating a random gloablly usable number
	- Graud
		- Condition to meet if you decide to take the transition 
	- Invarient 
		- Forces you to the take transtion and exit the state
		- So: a state with invarient x<=3,
			- x<=3 must be ture, if you want to stay in the state
			- if the condition satifies: it does not mean it will remain in the state, if it can take other state it will 
	- Commited state
		- Its say if we get inside this state we must get out of it immediatly 
		- Just like: Invarrient
		- Its like a branching if statement
		- Its also comes when you want to an action immediatly, but under some condition. 
	Tricks
		- Making a boundary condition
			- Range of time(clock), where its okay to stay in the same state
				- Use invarient to force you out of a state (define the max)
					- Maximum wait before you take the transition
				- Use guard (define the minimum bound/condition)
					- Minimum wait before you take the transition
			- A clock 
				- Reseting the clock every time we enter a state and checking is clock has gone over some number
				- work.busy imply (work.waiting and z <12)
			- Using clock with a bool
				- Before entering a state: start the clock from 0, set enter = True 
				- Exiting the state: set the enter = False 
		- Propogating a signal
			- Set the next state as commited
			- So it you get kicked out immediatly as you get a chance to send a message for free

	- Update 
		- turn:=(me==1?2:1)
			- if me is true then 2 else 1
	- Parameter
		- const int[1,2] me , int[0,1] &req_self, int[0,1] &req_other
		- & can take input
	- Querys
		- A: All Path , E: Exist a path
		- []: Always , <>: Eventually 
		- Example: 
			- A[] not(P1.CS and P2.CS)
			- P1.CS: P1 is not in state CS
			- A[]Obs.taken imply x>=2 
				- Bascally: Obs.taken -> x>=2 , if Obs.taken is ture , then x>=2 true aswell?
	- The transitions that can happen is highlighted in RED
	- Through channels and syn 2 Objects are communicate with each other
		- So like calling reset! in P1 made Obs go to take state
	- A component can be represented by a template, can communicate using channels and synchronization
------------------------
Main Memory
	- 2 Simple process system consisting of CPU core and main memory
	- The cpu core should make 
		- Read and Write to 
			-random main memeory locations? 
			- to random locations?
	- Adress bus?
		- Values of address bus?
		- 4 bits 
			- 16 different rows/loaction
			-each row 4 cols
	- Read and write request 
	- Request time?
	- Uppaal random 

	- Common line in read and write operation
		-Read
			- writeM: 0 
			- outM : 0
			- addressM: 4 bit address
			- iM : send data 
		- Write
			- writeM: 1
			- outM: 4 bit data 
			- addressM: 4 but address
			- im: 0
		-writeM line decides wether to read or write

		Sloving read operation
			CPU
				- Something needs to send a signal to writeM saying its a read operation
					- writeM: if op == 'read' then set it to 'load'
						- transition from core to selectOperation randomly set local 'op'  to [0,1]
							- 0: read 
							- 1: write 
				- Something must give addressM some adress
					- Well the address need to be randomly selected
						- Address Location From: 0 to 15  
							- core to getAddress set the  GLOBAL variable "address" to some random number (DONE)
								- its GLOBAL becuase, when sync message is recreived memeory, it needs to use it as well
				- No singal is passed to outM

				- Once its decided its a read operation 
					- Send read signal 
					- wait for finish reading singal 
			Memory 
				- When message on read? is recieved, 
					- set the data from the required address
						- What data structures are avialable to me, in uppaal? 
						- there are 16 rows,so array size of 16
						- each row only hold:  
					- send message using finished!
				- When it finishes writing, how should the core know, time based?
					-The memory should complete read and write requests within 25-30 nanoseconds
					- 25<=t<=30
				- Verify that the core always receives responses to read requests within 30 nanoseconds but never before 25 nanoseconds
					-   coreClock <=25
					-   coreClock >= 30

Dont jUst generate 4 bits randomly
	- Do it in seperate bits

Debbug:
	- You cant set a message after commited state
		- what if there was a not staisfed guard, it cant go thtorgh
		- but commited means must go through
			- Dead lock
			- Time stops
	- Property A[] cpu.respReciever imply (cpu.cpuClock >= 25 and cpu.cpuClock <=30)
		- is giving me flase 
			- check condition 1
				-cpu.cpuClock >= 25 (ture)
			-check condition 2
				-cpu.cpuClock <=30
				- is cpuClock always under 30?
				- Normal Reading request takes longer than 30 seconds
					- What takes time in the system?
						- When I am in waitForMemory state 
							- The memory has to do the following things 
								- reeadyState
								- Starting Reading 
						- WHat is the constraints?
							-The model-checker can check invariant and reachability properties by exploring the state-space of a system, i.e. reachability analysis in terms of symbolic states represented by constraints.
			- Condition 1 fails
				- do i need isLoadLineSet?
					- its only being used in cpu
			- Bothe cpuClock and memeory clock starts running(rests) on newReq? newReq!
				- cpu watforMemory respond
					- It wait for the memory unitil memory has gone over these states
						- readstate (mc running) (cC = running)
						-startingreading (mC = paused)(cC = running)
						- finishing Reading (mc = paused)(cC = running)

				- Make it such that when cpu is in readyState, memory is in writing/reading pahase 
Complete

----------
Direct-Mapped Cache
	- cache??
	- Cache controller?
	-two-line direct-mapped cache?
		- line?
			- Is the cache block
			- Form lecture videos, its should be a template 
			- chache line length
				- IMPORTANT: it is no the length off entier cachce block, it is the lengths of where the memory block goes in
				- In the homework, the number of total number memory address in a block is 1, so cache line length = 1,
				- So we dont need to any bits for selecting address inside the block 
				- Thus C part cant be ingored. 
		- 2x(one-line cache processes)?
			- 2 Cache block
			- 1-line cache: length of memory block is just 1
	- cache starts off with an invalid state?
	-Read,write process between cache, core and the main memory
	-cache hit and misses??
	- Include a count of the number of cache hits and misses

The address bus comes send Req to cache (Uppaal 2/ 22:30)
	- Req/Address: = A + B + C 
		   = Tag(MemoryBlock) + CacheBlock(Line) + (Which address(Byteblock) of the memory block )
		   - Generate this address
	- Find the A and B section
		- b1,b2,b3,b4
	- Go to the given cacheBlock/ Use the least sf part of address to gps you way to the correct cache block 
		- Comepare the Tags value / Compare part of the generated address
			- Match: Valid/Hit
			- Not Match: Not Valid/Miss 
		- 
	- What is the length of A and B?
		- We know there are 2 cache line 
			- Number of bits needed to make total combination of 2: 1bit
			- Thus: A=3 bits , b = 1 bits
	- Is it possible to send icorrect tag in the A part of the address?
	- Do I make the CacheController wait for cacheline to update?
		- What if b4 is for another cacheline that is doing noting 
		- So I think its best to just check if the cacheline is in updating state before we make a request
	- Does cpu make request synchornously?
		- Meaning does it send 1 request then another?
		- Yes, it has to be. Others wise the tag feild will change
	-  When the cache controlle sends newreq, how it distinguish between which cachcline to send the req to? as both of them use newReq chan
		- have a int cacheLine as id foreach object, So that means I need to pass in a parrameter to setID 
		- How to pass a parameter to a construcotr ofr each object?
			-example: const int[1,2] me , int[0,1]  &req_self, int[0,1] &req_other
				- Decelaration: P(2 ,req1 ,req2 )
				-req_self is a variable that will accept another variable as an arugment
				- gobal: int req1= 1 , int req2 = 2  
	- Is the validBit a gloable shared thing or local unshared
		- Local
	- Does the cpu also randomly select which cache line to go
		- No, the cpu knows which cache line the tag should be in: Not randomly generated.
			- This is important becasue certain tags only be in cetrain cache line!
		- How does it know?

	Steps:
		- Model CacheController
			- Take b4 to direct it to the correct cache line
				- By sending a message using a channel
					- 1st message: Are you updatingTag?
					-2nd: Process the req
			- Wait fors singal from cahceline
			- Sends message back to CPU immediately 
		- Model CacheLine
			- Take b1,b2,b3 as Tags
			- Checks if b1,b2,b3 == localVariable(tagb1,tagb2,tagb3)
				- Match
					- Send siginal to CancheController 
					- Increment Hit counter
				- Miss 
					- Send singal to the to memory 
					- Wait for singal from the memory
					- Send singal to cache controler
					- Update the tag
					- Update the invaild bit to 1 iff 0
					- Send singal to cache controller telling you are ready for another request
Complete
------------------------------
Set-Associative Cache (NewestLect: 0:00 - 13:37)
- Two way set asscoiativity
- Usingg a random line-replacement strategy
	- random line replacement?
	- Verify make the system with set-ass perform better than the direct-ampped system
- Compare the behaviour of LRU and FIFO line-replacement strategies
	- LRU: Least recently used?
	- Fifo: first in first out?
	- Find a series of requests which performs better under LRU
		- When does LRU work?
		- When does FIFO work?
- The best solution to this will 
	- automatically extract the sequences from the core with the desired properties?

Question
	- What does Steven say about LRU , FIFO, and random in the the main set associativity lectuers?
		- 
	- How does set assosiative caching work?
		-Reading request:	
			- b= tells us which set of lines 
			- then we have to check each cache line simultaneously 
				- if it exist in any of the cache line then it's a hit
				- elesif it does not exist in any cache line then its is a miss
					- ask memory for data 
					- send the data back to cpu
					- write in one of the line. 
						- Which line to write in?
							- Selection medthod: 
								- Random, Least-recent-used, least used , first in first out
		-Write request
			- write in one of the line. 
				- Which line to write in?
					- Selection medthod: 
						- Random
							- Randomly selects the tag
						- Least-recent-used /last used , 
							- in set0, if both lines have not been used, then pick a random
							- maybe I can have a bit that tells me what line was used last time 
									- Hence: last used will be the other set 
									- have a used bit:
										- if line is just used
							- Problem:
								- Going through a large array multiple time,
								- Scan it through for something and then do it agian for another
								- Then, infact we would be wanting data from least recently used placed (start of the file)
								- But Least-recently-used replaces the line.
								- Cyclicc structure is bad for least-rescently-used because it get rids of the start
						- least used,
							- NOT NEEDED 
							- need counter for each line
						- first in first out
							- use a bit to represent which line was used first 
							- if the line keeps getting reused, its is highly liely that it may be firt one in and need to stay there as it keeps getting reused.
							- However, with fifo, you rplace it away 
								- Hence, replace heavilty used pages
							- How does this work?
								- Which ever line was filled in first, 
								- Replace that line 

	- How do I check each cache line simultaneously?
		- 1 value/combination/bit/b now means check mutliple cache line
		- The total number of lines 
			- Number of lines: (direct map components) * n (assosiavitvity number)
				- should be 2 
		- So set 0 has 2 lines (fully associative == 1 set only == look at all the lines of the cache) 
			- Meaning you dont need any bit 'b' because you only have 1 combination
				- Math: numberOfBits = log2(combination)
			- Hence:
				- b:0 bits 
				- a: 4 bits

	- How does LRU work?
		- Have a bit telling which one was just used
		- Replace the line with 0 
	- How does FifO work?
		- Which line was first in?
	- Do I keep the hit and miss counter for performance measuremnt?
		- How do I compare the porformace measurements agianst direct mapped system 
		- Buid DMA and SET_ASSC
			- Send same generated request at the same time, and use verifier to extract out a trace where the number of hits are greater
	- What happens is cpu wants to send a message but cache is not ready yet?
		 - cpu can only run if the channels become avialable 
		 - But make you lock down cache and make it wait for the cpu
	- The first request has to be when vaildBit ==0 
		- Hence, it automatically a miss
			- Hence, You have to perform a write op 
	- Am I incrementing the hitCountera or not?
		- NO, I need to do that
	- What happens if 1 of the cacheLines just relayed the message but the other starts to take the validBit ==0 route?
		- The things is: The cacheLine activated later, will complete the request 
		- If a request is completed
			- Reset the cache to listen for new request
	- Would it be a good desgin choice to send double message from cpu?
		- No, cpu does not know caches exist. Its just knows how to send data
	-

	Steps:
		- Address: 4 bit tag  and 0 bit b 
		- Create a cacheLine template
			- 2 instances 
			- When request is  check both 
		Read Req:
			- Cpu send adress
				- 4 bit tag, 0 bit b
			- CacheLine Recieves the request
				- Check if the valid bit is 0 or not 
					- if 0 send mem req
					- if 1 then compare tags 
						- if 1 off them match: 
							- Send resp back to cpu
					- Hit and misses are decided only after checking both 
						- have a localCheck
						- have a globalCheck
							- Make a decision: (hitBitLine1 or hitBitLine2)
								- if hit: increase the hit counter
								- else: increase the miss counter
							- when do I perform the global check?
								-  Have BigOrGate Template that does the following
									- does the global comparison for hit and miss 
										- Waits for cacheLine1Ready? and cacheLine2Ready?
											- So: 
												- In CacheLine I need to pass the parameter to distinguish cacheline
												- if line1== 1: send message on cacheLine1Ready! etc
								- Have RandomLineSelector that does the following
									- Selects a random line
									- How does a RandomLineSelector know when to start processing?
		- Verification
			- implement something where the CPU calls both cache models
			- easiest to just run the same queries/verifications on both models and compare the real time taken to verify the same properties
DEBUG:
	- saCacheLine0 is not being ran,When saCacheLine 1 is ran
		- In other words: request is only made to 1 cacheLine by CPU
	- Remember I Have to check all the line
	- Atm, when it's at bigOrGate it is expecting for the remaing cacheLine for it's Message  (Sloved)
		- Once, when 1 of the cache is dont cehcking
			- It can relay the request by call send CachReqAgain?
	- Atm, RandomLineSelector is waiting for the second cacheLine to be ready,but 
		- its stucking wating for bigOrGateResp
		- I think there are 2 ways
			- Make bigOrgate resend the request agian
				- I think this is  a better idea 
			- Relay the message inside the cache
	- It taking a blank transition instrad of a urgent one(SLOVED)
		- Urgent channelsL if both reciever, and sender is ready . Stop what you are going and take this 
		- Urgent channel is not doing what I thought it would do
			- Misunderstadning: What does it acutally do?
				- There will be no delay if transition with urgent action can be taken
				- If call! is called
					- Reciever recieves the shit immediately and is forced to take the transition
				- But in my case, program has option to not call call! 
				- Plus, it does not mean it will prioities the trasition
		- How to priotise trasistion 
			- May I can put a guard on the empty transition, so that its only taken if 
				- isCacheLine1Started or isCacheLine2Start == false
		- Its is not taking the resetCache! transition
			- I need the empty transition because 
				- cacheLine == !LinetoWrite
			- The frist time it goes around
				- it tries to reset, but the other line is not yet in the state to recieve the reset
					- The other line is not in the reset state because it has not yet recevievd the request
					- Thus: Ideally we want to take an empty transition, in this situation
				- totalCacheLineChecked is 2 but still the one of the other line is in start state why?
					- Who +1 the counter?
	- In the case 2 hit are found. 
		- I need to only sendCupResp! if other have not been sent.

	-When a reqIs complete Processing, I need to reset all the paths
		- Takes the following transition with:
			- totalCacheLineChecked <=2 , thus no reset
			- Try: see if you can call channels coming out of a state when the state is not active 
	- When the cpu is sending write request who is recieving it?
		- I might send the write to sendRandomLineSelectorReq
			- iff cachLine matches linetoWrite
				- It will just write and all is good
			- iff cachLine does not matches linetoWrite
				 - Then it will just go to start state 
				 - But we want it to  
	- Can I just use CacheLine template to for modeeling DMC aswell
		- Because we are doing it 1 by 1. 
			- So like, SAC then DMC  and we have 4 cachelines
			- For querying Tag 
				-  we can set queryCacheLine to b 
				- send message on queryTag?
					- itwill send back qtab1 ()

Redo (DONE)
	Templates 
		- SACacheLine Controller (Parralalised this Model)
			- Read Request:
				- Decides Miss or Hits (DONE)
					- Query Tag values from both cacheLines and validBit (DONT NEET)
					- Send message on broadcast checkTag channles
						- When the lines receive it, make them check and update it 
						- You can set the bit whil you check stuff like hit:= (b1 == tag1)  
					- need a bit represent the queryingCacheLine
				- Handels Miss or Hits
					- Hit (DONE)
						- Send resp back to cpu
						- sned CPU resp, immediately
					- Miss (DONE)
						- Start selector proccess
						- Send CPU resp, Cachline is Done 
			- Write Request (DONE)
				- Handel Miss == write request
					- start selector process
			- Handels the hit and miss counter 
		- Selector (DONE)
			- Choose 1 of the cacheLine with the required method
			- example:
				- select 1: In cacheLine
					- start to proccess iff cacheLine== selectedLine 
		- CacheLines(DONE)
			- Only start process req 
				- if selectedcacheLine == cacheLine 
					- Send confirmation to selector 
				 - Else goes to a badState
			- Read 
				- Sends its tags value back to CacheLine Controller
				- Read and ValidBit==1 and hit is already taken care of from the controller
				- Read and ValidBit == 1 and hit  == 0
			- Write
				- Changes it tag value
				- Contacts Memory to change tag value
				- Contact cache controller when done
		- Memory (Done)
			- Accpets request from CacheLines 
			- Send response back to cacheLines
		CPU (DONE)
			- Sets the address
				- Contacts CacheController 
NEXt:
	- Build a system with both system inside 
	- Simulate both begin sent at the same time
	- Must used the same generated address
	- Verfiy: Because the cpu is making the same request verifer to extract a trace where number of hits is bigger in this one that the other
	- Whole of the cache is in 1 proccess
		- CacheLines are variabels: Array of arrray 
Templates
	 - Cache Controller (DONE)
	 	- Recieves the request from CPU
	 	- Passes the message to SAC then pass the message to DMC 
	 	- Pass the messsage T
	 	- Chan: urgent chan newCacheControllerReqToSACC , SACCResp,  newCacheControllerReqToDMC , DMCResp;
	 -Direct Mapped Cache DMC (DONE)
	 	- Recieves request from DMC Controller not CPU
	 	- Send Resp to cache controller not cpu
	 	- Responds to query from DMC controller
	 	- Handel Read write and validBit ==0 cases
	 - DMC controller (DONE)
	 	- Recieves message from CacheControoll
	 	- Pass the mesage to appropriate channel depending othe b value
	 	- ReadRequest
	 		- Decide Miss or Hit
	 			- Query the tag from 1 of the cacheLine 
	 			- No neeed queryingCacheLineBit, use b value
	 		- Handel Miss or Hit 
	 			- Hit 
	 				- Send Cache Controller resp
	 			- Miss
	 				-Selects one of the cacheLine depending on the b val
	 				-When the cacheLine reports Done, send cache controller back the message 
	 	-Write request == (handeling miss)
			-Selects one of the cacheLine depending on the b val
			-When the cacheLine reports Done, send cache controller back the message 

	- Finding a trace where the number of hits in SA is greater than in DMC
		- DMC counter
			- hitCounterDMC, missCounterDMC
		- SAC counter
			- hitCounter , hitCounter
		Query:
			- imply: p - > q
				-  whenever p holds q will eventually hold.
			- E<> ( (totalReqCompleted <= 1000) imply (hitCounterDMC < hitCounter) )
				- if total requests exceeds whatever limit you've set, that statement becomes true
				- because it becomes false imply something, which is always true
				- hence your verification will succeed, but it will not necessarily prove that a sequence exists

	- V3 
		- Try to play around with boadcast channel
			-A set of edges in different processes can synchronize if one is
			emitting and the others are receiving on the same b.c. channel. 
			-https://www.seas.upenn.edu/~lee/09cis480/lec-part-4-uppaal-input.pdf
		- Broadcast channels 
			- All the process move to a new state at the same time
		- V2 has to many templates 
			- Henece, many state
		-Template
			-SAC 
				- Checks 
	- LRU Selector
		- How does LRU work?
			- Hit == Bring the line to front of the list
			- Miss == Replace/write to the last line in the list 
				   == Bring the last line of the list to most forward
		Steps 
			- Need to know which line got hit
				- 0 or 1?
				- cacheLine0Hit and cacheLine1Hit tell me where the hit was

	- FIFo Selector
		- Change/replacing a line is based on age
		-first in first out
			- use a bit to represent which line was used first 
			- if the line keeps getting reused, its is highly liely that it may be firt one in and need to stay there as it keeps getting reused.
			- However, with fifo, you rplace it away 
				- Hence, replace heavilty used pages
			- How does this work?
				- Which ever line was filled in first, 
				- Replace that line 
		- Its not about which cachLine/block was used first.
		- Its about wh
		Steps:
			- Hit == That Line is the next victim
	- How to use a fking list?
		- def: int n1[length] = {1,2}
		- recall: n1[length-1]


Debug:
	- updataTag cann call the channeld (SLOVED)
	- someone already called the channel in saCacheController (SLOVED)
		- It was updateTag itself
	- SACCResp is recieved (SLOVED)
		- Waiting for DMC, but its stuck on compareTagDMC?
			- Are cacLineDMC1/0 okay?
	-cacheLineDMC1 is stuck on a state
		- no path to go for read==1 and vlaidBit == 1 and hit == 1
			- Thats should have been handled dmcController
			- Everything is correct but someone changed hit==1

Question:
- Least-recently used == Fifo
	- Least- recently used 
		- Replace the block that is not used for the longest
		- Needs to keep ordered list of N items for an
		N-way associative cache, that is updated on
	- Upon hits and misses lines is placed forward in the list 
		- it wont alternate between 0 and 1 because, its a line has 2 hits consecqutivly, the line is still placed next
 every access
	-Fifo
		- Replaces the oldes item in the cache
		- (expiry with age)
- How do I connect it to the main CPU?
	- Fifo and Lru both needs SaCacheController
	- SaCacheController is making a broadcast request
	- Looks like we need 2 SaCacheController,
		- 1 for LRU 
		- 1 for Fifo
		- 
	- CacheController is the one sending request to models
- I want to have 2 SAcacheController Instacnees
	- 1 using LRU selector 
	- 1 using fifo selector
	- The problem is both the instances will be sharing global variables 
		- cacheLine0Hit, cacheLine1Hit (SACC and CL)
		- hitCounter/ missCounter (SACC)
		- hit (SACC and CL)
		- selectedCacheLine(CL)
	- Is it possible to make these variable local?
		- The variables used by SAACC only can be made local
- There seems to 2 way I go about this 
	- Make a single SACC 
		- First goes through LRU and then FIFO
		- NEED:
			- 4 new cacheLines - 2 : Because I can use the existing variable used for random
			- 4 new counter variables 
			- 2 new hit variables
		- But Extra state may need to be added to compareTags 
	- Make 2 template SACC 
		- Each one does one of LRU and FIFO individually
		- Need:
			- To duplicate all the variables
	Steps:
		- Make 2 tempalte SACacheController (DONE)
			- Make the counters local vaitable 
			- Make a golab selector swtich variables 
				- useFifo == True 
				- useLru == flase
			- It send a message in boradcast chan to all selector 
				- Not all will run it, because they have a bool switch eg useFifio
				- Thus it is important to turn of the turn off that swtich when done using and the turn the oother
								
		-Make 4  cacheLines (DONE)
			- 0,1,2,3
			- for lrusLineselection always select between 2 and 3 
		- In cache controller,have the following states that activate when part2 == 1
			- Everything other variables can be reused if I send
				- proccess the request in linear fashion
				- fifo and then only start processing using lru
					- Currently, if it send a barodcast message, both SACC for fifo and lru wil starting runnging
						- In the SACC, only use the broadcast channel if part1 is true ()
						- If it is part 2: make 2 different new chanells
							- newCacheControllerReqForFifo?
							- newCacheControllerReqForLru?
				- turn off the useFifo resp is received and turn on useLru swtich and vice vers a

Debug:
- Cachelin is waiting for selector yo send message
- CacheController broadcast a message 
	- What we want is that there are 2 saCacheLine, each handeling Lru or Fifo request 
		- This is proved by: us putting the hitCounter and missCounter to local variables
	- Atm: We did create 2 instances of the saCacheLineController but 
		- when new request come in for 
			- newCacheControllerReqForFifo? both of the controllers run it 
			- because the condition is only: part2 and read
		- to make sure that 1 controller handels one of lru,
		- try: giving id parameter to saCacheController
			- and only running the lru if the id == 1
				- 0:random
				- 1:lru
				- 2:fifo
- Why is there so many hits on saCacheControllerLru
	- current lur hitCounter == 23
	- lru is sending compareTag to cacheLine0 and cacheLine1 but it should be sending it 2 and 3
		- cacheLine2 and cacheLine3 broadcast is blocked because
			- cacheLine2 : 2==1 
- Why do Lru and Fifo have the exact same counter?
	- saCacheController is incrementing the misscounte. 
		-becuase hit==0, why is hit 0,? 
			- hit is set to 0: (cachLine0Hit == false and cacLine1Hit == fasle)
			- who is setting the cacheLine0Hit and cacheLine1Hit to false?
				- It is set to false, when compareTag! is called to the following places
					- cacheLine0
						- is able to compare  (shouldn't be enabled)
					- cacheLine1
						- is able to compare (should not be enabled)
					- cacheLine2 
						- is able to compare (should be enabled so that This template can set its mark on cachLine0Hit)
					- cacheLine3 
						- is able to compare (should be enabled so that This template can set its mark on cachLine1Hit)
				- I want such that when lru call compareTag 
					- only cacheLine2 and cachLine3 compare their tag

				- Now only cacheLine2 and cacheLine3 mark there presence know in cacheLine0Hit and cacheLine1Hit 
					- In compare stage they are comparing local variable with b1...b4
						- Who is setting their local variable
							- it is set when they update their tag. It is set to b1...b4
- Why are the following the same?
	- cacheLine0 == cacheLine3
	- cacheLine1 == cacheLine2 
---------------------------------------------------------
VIDEO
	- A tour on you models and how they satisfy the relevant properties
	- How does the size of the model affect the amount of time taken to perfomr verification
		- How to change the size of the model
			- What could we possilby change about the model?
				- 4 bit address bus?
					-What happens if I make it a 5 bit....64bit address bus?
						- Start with 4bit,5,6,7 and look at what effect that on time taken 
				- 2 cacheLine?
	- If I play around with number of bits
		- keep number of cacheLines constant
	- If I play around with number cacheLines 
		- keep number of bits the same 
SCRIPT:
	- Main memory(DONE) 
		- In this section Cpu sets address and load bit randomly
		- And Sends the request to memory.
		- Upon recieving the request, memory checks, whether to write or read.
			- It uses graud set the resp time's lower bound and ensure that its does not send the Cpu resp before 25 nanosec
			- It uses invarient to set the resp upper bound and ensure that is send response at maximuim of 30 nanosec
		- I verify that the Cpu gets response within in 25 to 30 nanosec everytime by 
			- Having a timeout state, Cpu enters this state if it recieves the response to early or too late 
			- In verifery I check, if there exist a path where cpu enters this state which fails
			- Proving that it always recieve the resp within the required time bound
	- DMC(DONE)
	- DMC vs RandomSetAss
		-  to verfiy that there exist a series of request where 1 model does better than other by finding a path where number of hits in one the model is greaeter than the other
			- 

	- Experiements 
		- 2 parts 
			- Checking time 
			- Increasing the number of cacheLine
		STEPS:
			CACHE LINE
			- Increasing the number of cacheLines 
				- Basic Logic how DMC works
					- I have CPU, that call on a channel 
						- All the cacheLines listen on this channel 
						- if their id matches with the b value 
							- They start processing the request
			- Bits need to represent the total cacheLines
				- 2bits:1,2,3,4
				- 3bits: 1,2,3,4,5,6,7,8
			- I will need to used 4 bits (keeping the number of bits the same)
				- but use 3 bits for for b value
				- Do I just go and create 5 tempates and check indiviudal bits?
					- Thats one way
					- Need to pass in 3 int in the cacheLine parameters 
					-Need to check for if all the bits are equal 
						- cacheLineb1 == b2,  cacheLineb2== b3,...
						- We only update tagb1
						- hit and miss only depends on tagb1
			TIME
			-How Do I check if the time has increased or decreased?
				- A--> B happen within time t (This is not the syntax)
					-Meaning: When we get to A, B happens eventually within time t
						- Meaning: Think it like: time taken go from (A to B) and (out of B)
					- How can I use it?
						- A(Start state) --> B(CompleteState) eventually happens within time t
						-B == (CompleteState)
							- Have an invarient in B??
						- A == (Any other start state)
						- b == (boolean "doing")
						- t == (max time doing stay turned on)
						- z == clock
						- Verify: A[] (b imply z<t )
							- A[] ("doing" imply clock < maxtime + 1)
							- You are saying: whenever, if "doing" is switched on, it always between maxtime
					- Steps:
						- When leaving the startNode, turn on doing and start the timer
						- When you leave the end node, turn "doing" off
						- Verify:

		- DMC
			- Number of cacheLines
				- 2,3,4,5,6

-----------
Lectures
	-Video 2
		- Boolean Algbrea
	- Video 3 
		- Circuit of ALU
	- Video 4
		- Registers circuit
		- RAM from registers
	-Video 5
		- introduction different memory
			- data/ RAM
			- instruction/ ROM
		- A
	- Video 6
		- Instruction types
			- A instruction
			- B instruction
		- Types of Regiester
			- A : Hold address 
			- D : Hold data
			- M(NOT A REGISTER) : Data held in the ram at the location specifed by the A register
	- Video 7
		- Von Neumann Machine 
			- Connecting input and output devices 
			-Stored program concept 
				- Memory holds the program
		- Building Instruction Memory
			- Adress bus
	- Video 8
		- Building CPU 
		- How instructuions are processed
	- Video 9 
		- Accessing the memeory
			- RAM
			-ROM
	-Video 10(Transcript avialable)
		- Desinging a decoder
		- Instruction Pipelining 
	- Video 13
		- Direct-Mapped Cache
	- Video 14
		- Set Associative cache
		- Ways of wirting to cache
			- Last recently used
			- Last in first out
			- Last used
			- Random
		- Other caching problems
	- Video
		- Cache Summary(35:30)
			- Dirrect/associatve
			- Write policies
				- write-back/through
			- Multi-level caches
			- Cache coherency
				- snooping
				- mesi protocol
		-NEXT: Instructions sets Summary (36:40)
			-


---------
Uppall lecture 2 
Safety propety:(Basically checking negation of liveness property)
    - Something bad does not happen
    - Does there exist a path, where eventually  I get a bad state 
    - Forexample, a bad state is reacheable if response is not made in time 
        - We could send it to a state only if certain time is passed
        -How to do: 
            - Have a new template and some goalbal variables, the template will go to a bad state if time exceeds out
Liveness Propery:
    - A-->B 
    - Eventually something good it will happen


A->B within t (Technique 1)
    - Add a clock z
    - At the starting state set the timer to 0
    - And check the timers value at the other states 
    Example: 
        - P.currentState --> P.goingState
        - A state becomes true when the arrow coming towards it runs 
    - Verfiy: startState --> (endState and z<10)

A->B within t (Technique 2)
    - Samething as top
    - Extra: have a bool variable, goingToDest = true
           : when destination is reached, goingToDest = false
    - verfiy: A[](goingToDest imply z<t)
        - say: goingToDest==True holds inbetween startStart to destState
    - **************This method is to check how long a  bool variable stay true******
(Looking at this state, I learnt that everything that is in the back arrow is the stuff that is done in the state!!!)

A->B within t
	- Have a new test atomata, which set some global variables 
		- Share information this way 
	- OR
		- Use urgent channels 
			- declearation: urgent chan
			- time cannot pass when the communication is enabled == happens immediatley
				- So say you memeory send message to cpu immdealty 
			- BASCAILLY: immediate message sending without time passing 
EXTRA
	- Commited location
		- A state in which you cant any time in 
			- Its like having an invarient time == 0 
	- Urgent location
		- interleaving sementaics
			- view all the transition happining 1 at a time 
				- even if they have same instance of time
		- Time cant pass
		- Any timed transition is not allowed
		- So its like:
			- Example: From a startState you have multiple state you go to 
				- you want to take a certain transition first 
				- then you set dest state to urgent 
				- this will ensure that you will take that transition 

	- We cant have a time guard in an urgent location becuase we want it to happen straight away
		- What if we want (straight away + But wait for it to complete)
			- Solution: have a ready state, (to get here you will need some time)
					- Make the ready state urget or commited 
					- And have a fork from the ready state

-----------
TODO:
	- NEXT: Make a video


----
In break 
 - Do mediation
 - Do filler task 



